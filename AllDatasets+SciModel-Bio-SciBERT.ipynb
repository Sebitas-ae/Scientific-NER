{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1690993950254,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"CQ6H5sYFfFCM","outputId":"9f163421-3840-4dde-e99e-4cd38b7606b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data\n"]}],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"LyMVIljFrioE"},"source":["#External Databases"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28885,"status":"ok","timestamp":1690993979135,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"IeeP8a6fKXOX","outputId":"a142eecd-b597-43bd-9b3e-04e1e59ee4a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.20.0\n","  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.20.0)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.20.0)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.20.0) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.0) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.20.0) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.20.0) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.20.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.20.0) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 tokenizers-0.12.1 transformers-4.20.0\n"]}],"source":["#! pip install git+https://github.com/huggingface/transformers.git\n","!pip install transformers==4.20.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8411,"status":"ok","timestamp":1690993987533,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"_L4bHxBGsZk_","outputId":"421926ac-7a51-4b5b-a7e6-a5640767c11f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ray[tune]\n","  Downloading ray-2.6.1-cp310-cp310-manylinux2014_x86_64.whl (56.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (8.1.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.12.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (4.3.3)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.0.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (23.1)\n","Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (3.20.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (6.0.1)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (2.27.1)\n","Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.56.2)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.22.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (1.5.3)\n","Collecting tensorboardX>=1.9 (from ray[tune])\n","  Downloading tensorboardX-2.6.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[tune]) (9.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (23.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray[tune]) (0.19.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ray[tune]) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray[tune]) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->ray[tune]) (1.16.0)\n","Installing collected packages: tensorboardX, ray\n","Successfully installed ray-2.6.1 tensorboardX-2.6.2\n"]}],"source":["!pip install \"ray[tune]\" torch torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4077,"status":"ok","timestamp":1690993991605,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"qUkyduYfP8C2","outputId":"e57540d2-42e8-42d3-c167-724548bbfed3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch-tensorrt\n","  Downloading torch_tensorrt-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch<2.1,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0.1->torch-tensorrt) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0.1->torch-tensorrt) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0.1->torch-tensorrt) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1,>=2.0.1->torch-tensorrt) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=2.0.1->torch-tensorrt) (1.3.0)\n","Installing collected packages: torch-tensorrt\n","Successfully installed torch-tensorrt-1.4.0\n"]}],"source":["!pip install torch-tensorrt #==1.1.0 --find-links https://github.com/pytorch/TensorRT/releases/expanded_assets/v1.1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7800,"status":"ok","timestamp":1690993999400,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"UI0tseYdav7D","outputId":"33891570-fac4-4441-e9ce-16c4995fc589"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.14.2-py3-none-any.whl (518 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/518.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/518.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.2 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7325,"status":"ok","timestamp":1690994006720,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"},"user_tz":360},"id":"ApLO4wm1cmwo","outputId":"35f76343-b263-4b73-b42c-204a60e28589"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m41.0/43.6 kB\u001b[0m \u001b[31m973.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m839.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.22.4)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16165 sha256=8f3bd68cb0f400231b22873bc3cf8ea5e843c58e0d49db5f7d6079820dace6b6\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}],"source":["!pip install seqeval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCuB8MLZXiHj"},"outputs":[],"source":["#pip install accelerate -U"]},{"cell_type":"markdown","metadata":{"id":"52t8l945rf1Y"},"source":["#Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["d954d023b55d4221ab2ff9d1c11958fa","675ceaf5d35849b89e7e724b3a0bcac5","de35970352474f74964a16842642fa0b","0aad36d289b54104a3af8d54e2810c67","b40eb62ecfee44d6b66429d995070f6d","aa946f38ce44492f89f51f7730085b21","51a1d2b75dc54b85a1da482d7faec8a0","5d19905d73a2403d9f935e96d317ee70","03c7491b03e140ca91641ebec69b728c","a4884de943af4c7f88a40e658b7dab31","e034800afe0040b68f0bf36a602e3ff7","2a264b7a8aa146e68d7ec87ebd31b4e5","1a07428380d842558a015c33c50133b9","0e6c9115c51f4a7ca388d8ed8a40b9e6","51b5e31bb90149fa87e6c7a46c3ba28b","acf35e2b012a4908bfa1b7684d84692a","d0bda6b9fc294107b0974c8649cb3dfb","06fcfa646f2341deb5e9baa825485f90","710c1d0b690044f09b404c4a5d04faaf","cd9d61cff487442b9effad1e9abbfba1","f2c9753c7ada4105bb2fc578635f284c","a5e283f0d6384cf5b565359956a63f6d","b04f261a31264e6abd6832ece4948f3b","d77ff91b3f7148469b0fca726b3fecb2","efa12d957b894751a7d73fdce3a11a60","9fedbb73b3e74b9abea3cc8813441107","6793842716bf454d9f80df2f6cc9356c","2848168a464448bbaffcab4d7d8f7ee3","546c6e1b31464fa6a980b43679ac24ac","5c88474cf65246e1873c089f4f87ff19","a944bb3ff93f49e5adb2e08249463af5","c359e21fe6084f7bb451ab2fb5907d21","cd57f986b77f4b408bb91bc66fe96bd1"]},"id":"qSbdGMYCgquq","executionInfo":{"status":"ok","timestamp":1690994042180,"user_tz":360,"elapsed":35466,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"d8eeb19f-ff06-422c-957a-bd75e216c927"},"outputs":[{"output_type":"stream","name":"stdout","text":["4.20.0\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d954d023b55d4221ab2ff9d1c11958fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a264b7a8aa146e68d7ec87ebd31b4e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b04f261a31264e6abd6832ece4948f3b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","from google.colab import files\n","\n","import os\n","import re\n","import json\n","import string\n","\n","import torch\n","import torch.nn as nn\n","\n","import numpy as np\n","#import tensorflow as tf\n","from tensorflow import keras\n","#from tensorflow.keras import layers\n","\n","from datasets import load_metric\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","from seqeval.metrics import classification_report\n","from sklearn.metrics import precision_recall_fscore_support as prfs\n","\n","import tensorflow_hub as hub\n","from keras import backend as K\n","\n","import transformers\n","print(transformers.__version__)\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","from transformers.trainer_utils import EvalLoopOutput\n","\n","from transformers import AutoTokenizer, AutoModel\n","BertTokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n","BertEmbModel = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-DBrafz0KqEq"},"source":["#Loading Dataset NCBI"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vZ1ILIWq9do"},"outputs":[],"source":["class NCBIDataset(torch.utils.data.Dataset):\n","  def __init__(self, raw_dataset, max_length=250):\n","    self.raw_x = [x['tokens'] for x in raw_dataset]\n","    self.raw_y = [x['ner_tags'] for x in raw_dataset]\n","\n","    self.max_length = max_length\n","\n","  def tokenize_and_preserve_labels(self, sentence, text_labels):\n","    \"\"\"\n","    The tokenizer can split single words into multiple tokens - this breaks\n","    the labels, so we need to keep track of this!\n","    \"\"\"\n","    tokenized_sentence = []\n","    labels = []\n","\n","    for word, label in zip(sentence, text_labels):\n","\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = BertTokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        labels.extend([label] * n_subwords)\n","\n","    return tokenized_sentence, labels\n","\n","  def __getitem__(self, idx):\n","    tokens = self.raw_x[idx]\n","    labels = np.zeros((len(tokens)))\n","    for i, label in enumerate(self.raw_y[idx]):\n","      labels[i] = label\n","\n","    # This could be moved to __init__ to save time?\n","    tokens, labels = self.tokenize_and_preserve_labels(tokens, labels)\n","\n","    # Convert each token to an id number\n","    input_ids = BertTokenizer.convert_tokens_to_ids(tokens)\n","\n","    # add and adjust for special tokens\n","    input_ids = [BertTokenizer.cls_token_id] + input_ids + [BertTokenizer.sep_token_id]\n","    labels = [0] + labels + [0]\n","\n","    # Pad inputs\n","    input_ids = torch.tensor(np.pad(input_ids, [0, self.max_length-len(input_ids)]))\n","    labels = torch.tensor(np.pad(labels, [0, self.max_length-len(labels)], constant_values=-100))\n","\n","    for x in range(len(labels)):\n","      if labels[x] == 1:\n","        labels[x] = 9\n","      if labels[x] == 2:\n","        labels[x] = 10\n","\n","    attention_mask = torch.tensor([int(i != 0) for i in input_ids])\n","\n","    #return {input_ids, labels}\n","    #return {'input_ids': [input_ids], 'labels': labels}\n","    return {'input_ids': [input_ids], 'attention_mask': [attention_mask], 'labels': labels}\n","\n","  def __len__(self):\n","    return len(self.raw_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJBtnL2Jq_eQ"},"outputs":[],"source":["# Entity mapping, uses BIO tags\n","def Entity2ID(Sc_Entity):\n","  return {\n","        'B': 9,\n","        'I': 10,\n","        'O': 0,\n","    }[Sc_Entity]\n","\n","def ID2Entity(Sc_Entity):\n","  return {\n","        9: 'B-OtherScientificTerm',\n","        10: 'I-OtherScientificTerm',\n","        0: 'None',\n","    }[Sc_Entity]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2c1cCUnq_aP","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["5a088d9f0b0142879032e03c2806908b","0ca611188c3a415aac4e5d1ff0e556ce","458de8e2e8fe46a9825d5e13b80a22c4","9ebfd31e72e24da2b0b2ad189a16046a","5f598822f7a8449f9ec41d1846453e74","a2ad7dc7f26b40fb9df26dff16ff999b","b5286be853634ba6a5120ed027be73d6","c5acf1f9e0df4c6aaddb7a0486ab3054","ee99cc2548d5425e9b9c362e0bd775b2","f4c8db144dde48689e8e9f303c0ae2b5","889fb8c0408e4436a6f536d8ac2485c7","798dbc4ec8044e91aeae94b4d7888f4c","f1509974acb64513853e7918a2f6e250","42816cb113fd496389bdc7c2366299f7","4c1622b49b624dcdb6faf67d39781f69","73811ca1a6784a8888ace5c12e7de025","6746573afcfb4a1680dfe4c9fa9808af","bcf3958a87fe442097ee16ff7b0f0ef2","5a3b6f539c204e9b8a7f726ec55ea23a","f45ab7beef584c8c9d5e9bc57f3da47f","ec3f1738ccbd4420b2fc2afd91ccfb16","e7c46264ed8f4a73a290f8dcda46321d","d973d5a5deea4bc193c6ed95f8ac1e82","4561af2cc0ab44d69b5067fdaab96095","129dc291910e4b5788326ecd2dbda9ba","6631b73a228b40d7bbc7e54cce86f2ea","61b0062a44ca47178f04f0d1031d64f1","19feef6a1cd84bbdbb26f4b52dabe73e","e8c97c5540ec48d896dc78a23ab382df","26db51de410d4e01ac46418690839405","cc8a40d4b7cd4b3c916acc0b6070aea3","b913fe19266d4a9794620de23ee604ff","e98e5e89ae684a76bbd3e47f88aa1a07","6a45d884a8604cf49ef5e6cf308bbfbb","350586378fda483aba664b4d352546b2","1a798c5b8c584bcea0f1b09c730f02cb","62f20e042782402f81649938dde22444","aa5d2ee3538e446b8180c94190418ad1","8d474deb13584625a7087a4a5792922a","0001d73aff254cc2be8220d5f625d13e","f818a411d6fe499e81464e3d5e4679b5","41a1a4d33723447aa4f19f8921536757","82634e7ce59d4156abca84f2a5c961ce","46475a1560ef46d3b8e95d7d3f20ebe0","4dfd13497ad34c13be09821a30a37947","58b0fa9d33cb4e409e7484a99d3718f9","4fdd238ecd3345fda14bc71fb5aea724","90b005ca349f46818eb5889ad779535b","4ceaa9d99194485fa037be0078843f33","5b3f486080234649be25b9b5d7ff92ac","dad14e93411e4041a23225def1af11fa","424cb12c8815409da5c319b11486b459","30c9b5d7c90a4251890368cc8f0c52e5","b85a1db667c947f8b93089371532b8f0","c5fb5438613b473ea274f05343c1393b","fadac24a681345aab79df79f93699644","d1418b4f5cc441ffb8aa5e2d1a8fe536","66629eb67b5a4fa194909e06b8a9a22b","3f924c59275944158ea3cad74de931f2","b25ada84411046dd859770896a43c4ea","cb554b554025478787d9d226a4e4d87a","7a7a6a9ce5a34c87bb4e720caf154e5c","805a1b3d27d84a9aabb6090d7830d78e","69ed47d0e17b4a8f8b213e5cde02d691","912e5c2aeb7e4f61a0d2b5343a00cfbf","f4e5d14e6dda4a82a61dff2e405a1bd8","ff83ab45e805404d9d66c0050da271cf","92877ebdcc064b98b27ca3fdcea8695c","4fae413c489b4257ab692373a0abdb53","10847d518f8d413580cd6cd40eefeb39","5a0076d589c041eaa81c669320f54050","484d8defb6874fe5a00819ac240aab00","175d64d4ea1e4949b782291bc30d4075","fb3a28883c8a4772a518cf6e0dd2b580","a33033a066164223aefc6ede20dbd4e8","4d60a91ea20a4007a048af0c02dfb334","436c8a604b1f4b67ab9a1a8f902ae875","681c78ceef3e4a6180acdba726206bcd","9b006c29560c4ddfa88251222fedfe38","055ca7cc9dc84526a1ed734b67492f10","1eb120675114440695015f491901f647","7932d67fb1e245fcb4bf4aef90b9f299","06bf1f89ddb243f39a10cabbe011179a","45557893bd674a3f852bce63b2ac7c4a","cf739397926542ea97d2d004c00b438b","6be6e0f52c2843fab68fe4f2281ff45f","e5747abca28f45038a709239c56149e9","84aa73035c8443a88062517dee8f9cfe","a42dfbc6b2f34cf3a168d0f0c513eac1","cf831c2f7f7f4571abca0489c25927b0","27190639697547dbba180ed49be80798","6403bdfc30fb48bca2930a16cd79bab6","4a0917ada55240c59b13dd6566c119a9","046d3b5f357846be9df735562f83d3a1","2edd6eb6dd154c92968e29821958f985","3934c07d848e4a51ada4ec6ac4fe05e8","9820febb62f94f1d87746b87ef04ca02","30a9ff020fa84b0bbabc052d52e30358","6a88fbe9223f4bd1b49ec5e79efbd062","a0106b98a1964606bf83a3ffe130b226","e8ab8611237a4d6cb732d534cc2322b6","a7a9c82388054bcdb8ecc9c422d741bb","272e39b670fe4bb6b9dbb5ae4e18cc6f","c14012b3bc454f8cbbb47c698fefeb3f","533f3bcb4a0148b689fde4052169cc7c","7f91cd1b50114664830628918891d3d9","93f30ff688cd4654a0d84c3e6b0dc6a8","09c53bc7b9d849559cdfc128a4a9c3f2","3f3f2e9260634f65b3a2599afb3afb04","f7ae7dd7c11b458fb3f5694af088c04f","5922f5ca274b486c92a1e678660e430b","2976b431b04a4309b08574197d78a650","fe53e57d3031403f95b7814af640f5f1","eca14e25cc2e46c597a6b9839e3e1f77","d7e376a9d61b4a35b62d9d627253dc58","73ddacfd9f034b7786d043a940dd3e3c","e2fae04c32ce4dff9a897d05adb9a806","250b81e633014ff39da1606024bd7c6f","e6048090d32d414ca2f2f600497148ef","36ff535b73aa41cbb3f8aa8e680bc649","9d5efedfc60449a6ae8b20ac8852ed30"]},"executionInfo":{"status":"ok","timestamp":1690994066555,"user_tz":360,"elapsed":24378,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"d4347e7d-bd75-49b1-9c34-80e9946837c0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/5.83k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a088d9f0b0142879032e03c2806908b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading metadata:   0%|          | 0.00/3.45k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"798dbc4ec8044e91aeae94b4d7888f4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading readme:   0%|          | 0.00/9.70k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d973d5a5deea4bc193c6ed95f8ac1e82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a45d884a8604cf49ef5e6cf308bbfbb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/284k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dfd13497ad34c13be09821a30a37947"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/51.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fadac24a681345aab79df79f93699644"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/52.4k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff83ab45e805404d9d66c0050da271cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"681c78ceef3e4a6180acdba726206bcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/5433 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a42dfbc6b2f34cf3a168d0f0c513eac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/924 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0106b98a1964606bf83a3ffe130b226"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/941 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5922f5ca274b486c92a1e678660e430b"}},"metadata":{}}],"source":["# Download dataset using datasets, might need to install it!\n","from datasets import load_dataset\n","\n","raw_train = load_dataset('ncbi_disease', split='train')\n","raw_test = load_dataset('ncbi_disease', split='test')\n","raw_val = load_dataset('ncbi_disease', split='validation')\n","\n","# Convert to torch datasets\n","train_NCBI = NCBIDataset(raw_train)\n","test_NCBI = NCBIDataset(raw_test)\n","val_NCBI = NCBIDataset(raw_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nFPiiZ7vq_Vq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994066556,"user_tz":360,"elapsed":53,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"ab41a9f0-6e2d-40f0-d47c-44dc95e934ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["924"]},"metadata":{},"execution_count":12}],"source":["len(val_NCBI)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"puC_JdGDeRkD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994077905,"user_tz":360,"elapsed":11396,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"17dc6225-f7bd-4c64-a0c0-1c251ce11f24"},"outputs":[{"output_type":"stream","name":"stdout","text":["500\n","{'input_ids': [tensor([  102,   111, 24243,   861,   153,  7503,  1070,  5703,   145, 16036,\n","          546,  7421,   579, 14957,   787,  3151,   111, 12157, 10636,  3430,\n","          214,  8437,   106,  1127,   190, 18260, 12242,  4655,   239, 12186,\n","          145, 20362,   579,   239, 12186,   546,   422, 10361, 30111,  1352,\n","         6030,   107,   137,  6130, 14025,   205,   103,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])], 'labels': tensor([   0.,    0.,    9.,    9.,    9.,   10.,   10.,   10.,   10.,   10.,\n","          10.,   10.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    0.,    0.,    0.,    0., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.],\n","       dtype=torch.float64)}\n"]}],"source":["local_hp_train_NCBI = []\n","local_hp_val_NCBI = []\n","for x in range(500):\n","  local_hp_train_NCBI.append(train_NCBI[x])\n","\n","for x in range(180):\n","  local_hp_val_NCBI.append(val_NCBI[x])\n","\n","print(len(local_hp_train_NCBI))\n","print(local_hp_train_NCBI[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a6gr2c9MDbNH"},"outputs":[],"source":["#train_NCBI[20]"]},{"cell_type":"markdown","metadata":{"id":"XEm8RAgPDipK"},"source":["#Loading Dataset SciTDM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ICN0rgXve6o1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994199645,"user_tz":360,"elapsed":121776,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"ba9e2608-a1b5-4b98-be47-eafe39a94bb5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-5c02b652-708b-468a-a964-081a868b7736\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-5c02b652-708b-468a-a964-081a868b7736\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving test_500_v2.conll to test_500_v2.conll\n","Saving train_1500_v2.conll to train_1500_v2.conll\n"]}],"source":["uploaded = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yf9yoQx4D7r9"},"outputs":[],"source":["class TDMSciDataset(torch.utils.data.Dataset):\n","  def __init__(self, raw_x, raw_y, max_length=250):\n","    self.raw_x = raw_x\n","    self.raw_y = raw_y\n","\n","    self.max_length = max_length\n","\n","  def tokenize_and_preserve_labels(self, sentence, text_labels):\n","    \"\"\"\n","    The tokenizer can split single words into multiple tokens - this breaks\n","    the labels, so we need to keep track of this!\n","    \"\"\"\n","    tokenized_sentence = []\n","    labels = []\n","\n","    for word, label in zip(sentence, text_labels):\n","\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = BertTokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        labels.extend([label] * n_subwords)\n","\n","    return tokenized_sentence, labels\n","\n","  def __getitem__(self, idx):\n","    tokens = self.raw_x[idx]\n","    labels = np.zeros((len(tokens)))\n","    for i, label in enumerate(self.raw_y[idx]):\n","      labels[i] = label\n","\n","    # This could be moved to __init__ to save time?\n","    tokens, labels = self.tokenize_and_preserve_labels(tokens, labels)\n","\n","    # Convert each token to an id number\n","    input_ids = BertTokenizer.convert_tokens_to_ids(tokens)\n","\n","    # add and adjust for special tokens\n","    input_ids = [BertTokenizer.cls_token_id] + input_ids + [BertTokenizer.sep_token_id]\n","    labels = [0] + labels + [0]\n","\n","    # Pad inputs\n","    input_ids = torch.tensor(np.pad(input_ids, [0, self.max_length-len(input_ids)]))\n","    labels = torch.tensor(np.pad(labels, [0, self.max_length-len(labels)], constant_values=-100))\n","\n","    attention_mask = torch.tensor([int(i != 0) for i in input_ids])\n","\n","    #return {input_ids, labels}\n","    #return {'input_ids': [input_ids], 'labels': labels}\n","    return {'input_ids': [input_ids], 'attention_mask': [attention_mask], 'labels': labels}\n","\n","  def __len__(self):\n","    return len(self.raw_y)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WYy-iTnlEU8K"},"outputs":[],"source":["# Entity maps\n","def Entity2ID(Sc_Entity):\n","  return {\n","        'B-TASK': 1,\n","        'I-TASK': 2,\n","        'B-DATASET': 7,\n","        'I-DATASET': 8,\n","        'B-METRIC': 5,\n","        'I-METRIC': 6,\n","        'None': 0,\n","        'O': 0,\n","    }[Sc_Entity]\n","\n","def ID2Entity(Sc_Entity):\n","  return {\n","        1: 'B-Task',\n","        2: 'I-Task',\n","        7: 'B-Material',\n","        8: 'I-Material',\n","        5: 'B-Metric',\n","        6: 'I-Metric',\n","        0: 'None',\n","    }[Sc_Entity]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxRNljBqETC0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994199648,"user_tz":360,"elapsed":15,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"3151f7fa-23cd-4ebc-b3a0-5b14916d5654"},"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'results', 'show', 'that', 'proposed', 'shallow', 'representations', 'of', 'sentence', 'structure', 'are', 'robust', 'to', 'reductions', 'in', 'parsing', 'accuracy', ',', 'and', 'that', 'the', 'contribution', 'of', 'alternative', 'representations', 'of', 'sentence', 'structure', 'to', 'successful', 'semantic', 'role', 'labeling', 'varies', 'with', 'the', 'integrity', 'of', 'the', 'parsing', 'and', 'argument', '-', 'identification', 'stages', '.', '.']\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 0, 0, 0]\n"]}],"source":["# Load raw data train\n","raw_x = []\n","raw_y = []\n","\n","cur_x = []\n","cur_y = []\n","with open('train_1500_v2.conll', 'r') as f:\n","  for line in f:\n","    if len(line.strip()) <= 3:\n","      raw_x.append(cur_x)\n","      raw_y.append(cur_y)\n","      cur_x = []\n","      cur_y = []\n","    else:\n","      line = line.strip().split('\\t')\n","      cur_x.append(line[0])\n","      cur_y.append(Entity2ID(line[-1]))  # use this for BIO tags\n","      # cur_y.append(Entity2ID(line[-1].split('-')[-1]))  # use this for span tags\n","\n","print(raw_x[10])\n","print(raw_y[10])\n","\n","# Create actual dataset\n","train_SciTDM = TDMSciDataset(raw_x, raw_y)\n","\n","#print(train[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nb6gP0ISYNFU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994199649,"user_tz":360,"elapsed":14,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"f81b9ff2-b5df-416a-f925-fcb8565281d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["['We', 'evaluate', 'our', 'approach', 'on', 'three', 'datasets', ':', 'TriviaQA', 'unfiltered', '(', ',', 'a', 'dataset', 'of', 'questions', 'from', 'trivia', 'databases', 'paired', 'with', 'documents', 'found', 'by', 'completing', 'a', 'web', 'search', 'of', 'the', 'questions', ';', 'TriviaQA', 'web', ',', 'a', 'dataset', 'derived', 'from', 'TriviaQA', 'unfiltered', 'by', 'treating', 'each', 'question', 'document', 'pair', 'where', 'the', 'document', 'contains', 'the', 'question', 'answer', 'as', 'an', 'individual', 'training', 'point', ';', 'and', 'SQuAD', '(', ',', 'a', 'collection', 'of', 'Wikipedia', 'articles', 'and', 'crowdsourced', 'questions', '.']\n","[0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["# Load raw data test\n","raw_x = []\n","raw_x = []\n","raw_y = []\n","\n","cur_x = []\n","cur_y = []\n","with open('test_500_v2.conll', 'r') as f:\n","  for line in f:\n","    if len(line.strip()) <= 3:\n","      raw_x.append(cur_x)\n","      raw_y.append(cur_y)\n","      cur_x = []\n","      cur_y = []\n","    else:\n","      line = line.strip().split('\\t')\n","      cur_x.append(line[0])\n","      cur_y.append(Entity2ID(line[-1]))  # use this for BIO tags\n","      # cur_y.append(Entity2ID(line[-1].split('-')[-1]))  # use this for span tags\n","\n","print(raw_x[10])\n","print(raw_y[10])\n","\n","# Create actual dataset\n","test_SciTDM = TDMSciDataset(raw_x, raw_y)\n","\n","#print(test[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iH9xrFbXFG0g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994200000,"user_tz":360,"elapsed":363,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"8a3e5c85-4acf-4b3c-be8a-7a061b4c7f0f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(486, 1522)"]},"metadata":{},"execution_count":20}],"source":["len(test_SciTDM), len(train_SciTDM)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xW0jveILkHM"},"outputs":[],"source":["#train[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sFt85TdsW7PO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994204080,"user_tz":360,"elapsed":4082,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"1eead52f-f3d0-4e55-9536-c066251036f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["500\n","{'input_ids': [tensor([ 102,  185, 3138,  111, 8709, 1910,  214, 5373,  547, 3838, 2683,  168,\n","        9810, 8158,  121, 1323, 4371,  205,  103,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])], 'labels': tensor([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,\n","           5.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.],\n","       dtype=torch.float64)}\n"]}],"source":["local_hp_train_SciTDM = []\n","local_hp_val_SciTDM = []\n","for x in range(500):\n","  local_hp_train_SciTDM.append(train_SciTDM[x])\n","\n","for x in range(180):\n","  local_hp_val_SciTDM.append(test_SciTDM[x])\n","\n","print(len(local_hp_train_SciTDM))\n","print(local_hp_train_SciTDM[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jX2hTV7sFBhn"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"igV5vNz9FSFN"},"source":["#Loading Dataset SciERC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ppqrDMrIFSFi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994228696,"user_tz":360,"elapsed":24651,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"06ef04c3-f2cd-4bf4-d9d2-6841282af69b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-cde5c1a1-21d7-40e3-b022-f888993aa526\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-cde5c1a1-21d7-40e3-b022-f888993aa526\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving dev.json to dev.json\n","Saving test.json to test.json\n","Saving train.json to train.json\n"]}],"source":["uploaded = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IR8fDCLnap-m"},"outputs":[],"source":["class SciERCDataset(torch.utils.data.Dataset):\n","  def __init__(self, raw_data, entity_map, max_length=250):\n","    # Need to fix sentence offset for labels!!\n","    for i, sample in enumerate(raw_data):\n","      sent_offset = 0\n","      for j, sent in enumerate(sample['sentences']):\n","        for k, ner in enumerate(sample['ner'][j]):\n","          raw_data[i]['ner'][j][k] = [raw_data[i]['ner'][j][k][0] - sent_offset,\n","                                      raw_data[i]['ner'][j][k][1] - sent_offset,\n","                                      raw_data[i]['ner'][j][k][2]]\n","        sent_offset += len(sent)\n","\n","    sentences = [x['sentences'] for x in raw_data]\n","    self.raw_x = [sent for sublist in sentences for sent in sublist]\n","\n","    ners = [x['ner'] for x in raw_data]\n","    self.raw_y = [ner for sublist in ners for ner in sublist]\n","\n","    self.entity_map = entity_map\n","    self.max_length = max_length\n","\n","  def tokenize_and_preserve_labels(self, sentence, text_labels):\n","    \"\"\"\n","    The tokenizer can split single words into multiple tokens - this breaks\n","    the labels, so we need to keep track of this!\n","    \"\"\"\n","    tokenized_sentence = []\n","    labels = []\n","    prev_label = 0\n","\n","    for word, label in zip(sentence, text_labels):\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = BertTokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        if label != 0:\n","          labels.extend([-100] * n_subwords)\n","          labels[-1 * n_subwords] = label\n","        else:\n","          labels.extend([label] * n_subwords)\n","\n","        prev_label = label\n","\n","    return tokenized_sentence, labels\n","\n","  def __getitem__(self, idx):\n","    tokens = self.raw_x[idx]\n","    labels = np.zeros((len(tokens)))\n","\n","    #For Span\n","    for ner in self.raw_y[idx]:  # Returns [start_idx, end_idx, string label]\n","      assert len(tokens) >= ner[0], '{}, {}'.format(tokens, ner)\n","      ner_name = 'I-' + ner[-1]\n","      label = self.entity_map(ner_name)  # Get the integer label\n","      labels[ner[0]:ner[1]+1] = label\n","      labels[ner[0]] = label - 1\n","\n","    #For BIO\n","    #for ner in self.raw_y[idx]:  # Returns [start_idx, end_idx, string label]\n","    #  assert len(tokens) >= ner[0], '{}, {}'.format(tokens, ner)  # Double checking the labels are correct\n","    #  ner_name = 'I-' + ner[-1]  # assume all are \"I\" labels\n","    #  label = self.entity_map(ner_name)  # Get the integer label\n","    #  labels[ner[0]:ner[1]+1] = label\n","    #  labels[ner[0]] = label - 1  # Change first one to \"B\" label\n","\n","    # This could be moved to __init__ to save time?\n","    tokens, labels = self.tokenize_and_preserve_labels(tokens, labels)\n","\n","    # Convert each token to an id number\n","    input_ids = BertTokenizer.convert_tokens_to_ids(tokens)\n","\n","    # add and adjust for special tokens\n","    input_ids = [BertTokenizer.cls_token_id] + input_ids + [BertTokenizer.sep_token_id]\n","    labels = [0] + labels + [0]\n","\n","    # Pad inputs\n","    input_ids = torch.tensor(np.pad(input_ids, [0, self.max_length-len(input_ids)]))\n","    labels = torch.tensor(np.pad(labels, [0, self.max_length-len(labels)], constant_values=-100))\n","\n","    attention_mask = torch.tensor([int(i != 0) for i in input_ids])\n","\n","    return {'input_ids': [input_ids], 'attention_mask': [attention_mask], 'labels': labels}\n","\n","  def __len__(self):\n","    return len(self.raw_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TlMNAfW3gfGp"},"outputs":[],"source":["def Entity2ID(Sc_Entity):\n","  return {\n","        'B-Task': 1,\n","        'I-Task': 2,\n","        'B-Method': 3,\n","        'I-Method': 4,\n","        'B-Metric': 5,\n","        'I-Metric': 6,\n","        'B-Material': 7,\n","        'I-Material': 8,\n","        'B-OtherScientificTerm': 9,\n","        'I-OtherScientificTerm': 10,\n","        'B-Generic': 11,\n","        'I-Generic': 12,\n","        'None': 0\n","    }[Sc_Entity]\n","\n","def ID2Entity(Sc_Entity):\n","  return {\n","        1: 'B-Task',\n","        2: 'I-Task',\n","        3: 'B-Method',\n","        4: 'I-Method',\n","        5: 'B-Metric',\n","        6: 'I-Metric',\n","        7: 'B-Material',\n","        8: 'I-Material',\n","        9: 'B-OtherScientificTerm',\n","        10: 'I-OtherScientificTerm',\n","        11: 'B-Generic',\n","        12: 'I-Generic',\n","        0: 'O'\n","    }[Sc_Entity]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awzlXu9Ugool","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994228698,"user_tz":360,"elapsed":58,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"78c351b5-6dbf-4696-d582-b4a9f210d174"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["350"]},"metadata":{},"execution_count":26}],"source":["train_data = []\n","with open('train.json','r') as f:\n","  for line in f:\n","    train_data.append(json.loads(line))\n","\n","test_data = []\n","with open('test.json','r') as f:\n","  for line in f:\n","    test_data.append(json.loads(line))\n","\n","val_data = []\n","with open('dev.json','r') as f:\n","  for line in f:\n","    val_data.append(json.loads(line))\n","\n","#train_data[3]['sentences'][0], train_data[3]['ner'][0], len(train_data[3]['sentences'][1])\n","len(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y92WU6R3dltN"},"outputs":[],"source":["train_SciERC = SciERCDataset(train_data, Entity2ID)\n","val_SciERC = SciERCDataset(val_data, Entity2ID)\n","test_SciERC = SciERCDataset(test_data, Entity2ID)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YyTtZEgcLv3C"},"outputs":[],"source":["#tokens = BertTokenizer.convert_ids_to_tokens(train[1]['input_ids'][0])\n","#labels = train[1]['labels']\n","#print(' '.join(tokens))\n","#print(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-2wczlALa-p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994228699,"user_tz":360,"elapsed":53,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"669740aa-26e4-4be6-f559-29e23828d8c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [tensor([  102,  6170,   165,   817,   147,   195,   428,   579,  2220,   579,\n","           2159,   191,   111,  2525,   131,  7395, 30113,   131,   111,  1222,\n","           1211,   198,  3862,  8503, 13510,  2057,   579,  8595,  4111,   205,\n","            103,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0])],\n"," 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n"," 'labels': tensor([   0.,    7.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    0.,    0.,    9., -100.,    0.,    0.,    0.,\n","            0.,    0.,    0.,    9.,   10.,   10., -100., -100.,   10.,    0.,\n","            0., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","         -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.],\n","        dtype=torch.float64)}"]},"metadata":{},"execution_count":29}],"source":["train_SciERC[0]"]},{"cell_type":"markdown","metadata":{"id":"SneST94BFvSI"},"source":["#Unifiying Loaded Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xUX2uIlrFvoK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994228699,"user_tz":360,"elapsed":49,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"56214e10-1e0f-4ce2-bdf8-197254b340ab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5433, 1522, 1861)"]},"metadata":{},"execution_count":30}],"source":["len(train_NCBI), len(train_SciTDM), len(train_SciERC)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rghT4EhmGOMq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994228700,"user_tz":360,"elapsed":49,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"a69cfb30-bddd-47f5-c05a-29b5cf818bd4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(941, 486, 551)"]},"metadata":{},"execution_count":31}],"source":["len(test_NCBI), len(test_SciTDM), len(test_SciERC)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pBL5Wbi-GQF3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994228700,"user_tz":360,"elapsed":47,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"6c07c6ec-437d-4acc-99fb-f625e492e73d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(924, 275)"]},"metadata":{},"execution_count":32}],"source":["len(val_NCBI), len(val_SciERC)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zL4migU3GYg3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994228701,"user_tz":360,"elapsed":46,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"68930f49-c398-41df-f46f-8961b27dd592"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 500, 180, 180)"]},"metadata":{},"execution_count":33}],"source":["len(local_hp_train_NCBI), len(local_hp_train_SciTDM), len(local_hp_val_NCBI), len(local_hp_val_SciTDM)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DfZP3cxDGlf5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690994228701,"user_tz":360,"elapsed":45,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"3dfda3e5-edc7-4107-ff62-09c6089f471c"},"outputs":[{"output_type":"stream","name":"stdout","text":["8816 1978 1379 1000 360\n","{'input_ids': [tensor([  102,   106,   983,   422, 15162, 30118, 30130,   422,  6525,   121,\n","          106,  1454,   190,  5390, 30113,  5855,   422,   434,   528,  1887,\n","          137,   797,   147, 12886,   106,   787,   190, 11600,   147, 16745,\n","         1352, 10837, 29730,  7948,  4446,  1391,   145, 16745,  1352, 10837,\n","        15325,   546,   205,   103,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])], 'labels': tensor([   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    9.,    9.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n","           0.,    0.,    0.,    0., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.,\n","        -100., -100., -100., -100., -100., -100., -100., -100., -100., -100.],\n","       dtype=torch.float64)}\n"]}],"source":["train = train_NCBI + train_SciTDM + train_SciERC\n","test = test_NCBI + test_SciTDM + test_SciERC\n","val = val_NCBI + val_SciERC + local_hp_val_SciTDM\n","local_hp_train = local_hp_train_NCBI + local_hp_train_SciTDM\n","local_hp_val = local_hp_val_NCBI + local_hp_val_SciTDM\n","print(len(train), len(test), len(val), len(local_hp_train), len(local_hp_val))\n","print(train[2000])"]},{"cell_type":"markdown","metadata":{"id":"oGYV8ipcJ5fU"},"source":["# Pytorch Model Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFp2ZFd25KwK"},"outputs":[],"source":["class NerModel(nn.Module):\n","  def __init__(self, b_embeddings, emb_dims=768, ff_dims=14, out_dims=13):\n","    super(NerModel, self).__init__()\n","    self.sci_embeddings = b_embeddings\n","    self.embd_dropout = nn.Dropout(0.1)\n","    self.ff_dropout = nn.Dropout(0.1)\n","    self.ff = nn.Linear(emb_dims, ff_dims)\n","    #self.tanh = nn.Tanh()#\n","    #self.lstm = nn.LSTM(768, 100, 1, bidirectional=True)#\n","    #self.lstm_drop = nn.Dropout(0.4)#\n","    self.ff = nn.Linear(768, 14)#200\n","    self.ff_act = nn.ReLU()\n","    self.classifier = nn.Linear(ff_dims, out_dims)\n","  def forward(self, input_ids=None, attention_mask=None, labels=None):\n","    embds = self.sci_embeddings(input_ids=input_ids, attention_mask=attention_mask)['last_hidden_state']\n","    out = self.embd_dropout(embds)\n","    #out, _ = self.lstm(out)#\n","    #out = self.tanh(out)#\n","    #out = self.lstm_drop(out)#\n","    out = self.ff(out)\n","    out = self.ff_act(out)\n","    out = self.ff_dropout(out)\n","    out = self.classifier(out)\n","    return out"]},{"cell_type":"markdown","metadata":{"id":"7LthVVOhx_Sz"},"source":["# Metrics and Configs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZJjqYf2AKA8"},"outputs":[],"source":["def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    #print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","\n","import math\n","\n","def load_param():\n","  for n, v in best_run.hyperparameters.items():\n","    if n == 'seed':\n","      setattr(trainer.args, n, math.ceil(v))\n","      print(n, math.ceil(v))\n","    else:\n","      setattr(trainer.args, n, v)\n","      print(n, v)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjMXqFluyLCW"},"outputs":[],"source":["batch_size = 4\n","training_args = TrainingArguments(\n","    \"trained_scibert_ner_model\", # output dir\n","    learning_rate=1e-5,\n","    num_train_epochs=10,\n","    dataloader_drop_last=True,\n","    per_device_eval_batch_size=batch_size,\n","    per_device_train_batch_size=batch_size,\n","    logging_steps=50,\n","    save_steps=len(train) // batch_size,\n","    lr_scheduler_type='cosine',\n","    evaluation_strategy='steps',\n","    eval_steps=len(train) // batch_size)\n","#print(training_args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fabdHzMRybBR"},"outputs":[],"source":["def collator(batch):\n","  out =  {\n","      'input_ids': torch.stack([(x['input_ids'][0]) for x in batch]),\n","      'attention_mask': torch.stack([x['attention_mask'][0] for x in batch]),\n","      'labels': torch.stack([x['labels'].clone().detach() for x in batch])\n","  }\n","  return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dZluJPsy2eb5"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class FocalLoss(nn.modules.loss._WeightedLoss):\n","    def __init__(self, weight, gamma, reduction='mean'):\n","        super(FocalLoss, self).__init__(weight,reduction=reduction)\n","        self.gamma = gamma\n","        self.weight = weight #weight parameter will act as the alpha parameter to balance class weights\n","\n","    def forward(self, input, target):\n","        ce_loss = F.cross_entropy(input, target, ignore_index=-100, reduction=self.reduction, weight=self.weight)\n","        pt = torch.exp(-ce_loss)\n","        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()\n","        return focal_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLbpwNckLvV6"},"outputs":[],"source":["class MultilabelTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False, num_labels=13):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        logits = outputs\n","\n","        #weights = torch.tensor([0.1, 1.5, 1.55, 1.9, 1.75, 1.65, 1.9]).cuda()  # The no-class label has too many examples, we need to weight the loss - this probably needs further tuning\n","\n","        #weights = torch.tensor([0.1, 1.5, 1.2, 1.9, 1.75, 1.3, 1.85]).cuda()\n","\n","        #weights = torch.tensor([0.89, 1.73, 1.69, 1.79, 1.76, 1.7, 1.77]).cuda()\n","\n","        #weights = torch.tensor([0.89, 1.69, 1.65, 1.84, 1.75, 1.66, 1.77]).cuda()\n","\n","        #weights = torch.tensor([0.95, 1.6, 1.5, 1.94, 1.7, 1.55, 1.83]).cuda()\n","\n","        #weights = torch.tensor([0.12, 0.83, 0.78, 1.0, 0.88, 0.8, 0.95]).cuda()\n","\n","        #weights = torch.tensor([0.42, 1.5, 1.2, 2.0, 1.6, 1.4, 1.8]).cuda()\n","\n","        #weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]).cuda()\n","\n","        #weights = torch.tensor([0.1, 1.36, 0.93, 7.45, 2.66, 1.01, 3.51]).cuda()\n","\n","        #weights = torch.tensor([0.26, 0.95, 0.92, 0.99, 0.97, 0.93, 0.98]).cuda()\n","\n","        weights = torch.tensor([0.25, 0.98, 0.97, 0.97, 0.95, 1.0, 1.0, 0.99, 0.98, 0.97, 0.96, 0.98, 1.2]).cuda()\n","\n","        gamma=5\n","        loss_fct = FocalLoss(weight=weights, gamma=gamma)\n","        loss = loss_fct(logits.view(-1, num_labels), labels.long().view(-1))\n","        return (loss, outputs) if return_outputs else loss\n","\n","    def evaluation_loop(self, dataloader, description, prediction_loss_only=None, ignore_keys=None, metric_key_prefix=\"eval\", num_labels=7):\n","      args = self.args\n","      prediction_loss_only = prediction_loss_only if prediction_loss_only is not None else args.prediction_loss_only\n","\n","      self.model.eval()\n","\n","      all_losses = []\n","      all_preds = []\n","      all_labels = []\n","      for step, sample in enumerate(dataloader):\n","        for i in range(0, len(sample['labels'])):\n","          inputs = {}\n","          inputs['input_ids'] = torch.stack([sample['input_ids'][i].cuda()])\n","          inputs['attention_mask'] = torch.stack([sample['attention_mask'][i].cuda()])\n","          inputs['labels'] = torch.stack([sample['labels'][i].cuda()])\n","          labels = inputs['labels'][0].cpu().numpy()\n","\n","          (loss, logits) = self.compute_loss(self.model, inputs, return_outputs=True)\n","          logits = logits[0].cpu().detach().numpy()\n","          preds = np.argmax(nn.Softmax(dim=-1)(torch.tensor(logits)).numpy(), axis=-1)\n","\n","          all_losses = np.concatenate((all_losses, [loss.detach().cpu().numpy()]), axis=0)\n","\n","          preds = preds[labels != -100]\n","          labels = labels[labels != -100]\n","          all_preds = np.concatenate((all_preds, preds))\n","          all_labels = np.concatenate((all_labels, labels))\n","\n","      metrics = {}\n","      metrics['macro_f1'] = f1_score(all_labels, all_preds, average='macro')\n","      metrics['macro_precision'] = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n","      metrics['macro_recall'] = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n","      metrics['micro_f1'] = f1_score(all_labels, all_preds, average='micro')\n","      metrics['micro_precision'] = precision_score(all_labels, all_preds, average='micro', zero_division=0)\n","      metrics['micro_recall'] = recall_score(all_labels, all_preds, average='micro', zero_division=0)\n","\n","      metrics['macro_f1_no_o'] = f1_score(all_labels, all_preds, average='macro', labels=[1, 2, 3, 4, 5, 6])\n","      metrics['macro_precision_no_o'] = precision_score(all_labels, all_preds, average='macro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","      metrics['macro_recall_no_o'] = recall_score(all_labels, all_preds, average='macro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","      metrics['micro_f1_no_o'] = f1_score(all_labels, all_preds, average='micro', labels=[1, 2, 3, 4, 5, 6])\n","      metrics['micro_precision_no_o'] = precision_score(all_labels, all_preds, average='micro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","      metrics['micro_recall_no_o'] = recall_score(all_labels, all_preds, average='micro', labels=[1, 2, 3, 4, 5, 6], zero_division=0)\n","\n","      for key in list(metrics.keys()):\n","        if not key.startswith(metric_key_prefix):\n","          metrics[metric_key_prefix + '_' + key] = metrics.pop(key)\n","\n","      metrics[metric_key_prefix + '_loss'] = all_losses.mean().item()\n","\n","      return EvalLoopOutput(predictions=all_preds, label_ids=all_labels, metrics=metrics, num_samples=len(dataloader))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"infNapI_OmFr"},"outputs":[],"source":["def my_hp_space_ray(trial):\n","    from ray import tune\n","\n","    return {\n","        \"learning_rate\": tune.loguniform(9e-6, 1e-4),\n","        \"num_train_epochs\": tune.choice(range(5, 25)),\n","        \"weight_decay\": tune.uniform(0.0, 0.2),\n","        \"per_device_train_batch_size\": tune.choice([4, 8, 16]),  #<16 definetly not working\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-UT0niEma9q"},"outputs":[],"source":["#train[0]"]},{"cell_type":"markdown","metadata":{"id":"1Nh8Lcpvb_F4"},"source":["# Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6AqbEPyPK7O"},"outputs":[],"source":["def model_init():\n","    x = NerModel(BertEmbModel)\n","    x.sci_embeddings.requires_grad = False\n","    return x\n","\n","trainer = MultilabelTrainer(model_init=model_init,\n","                            args=training_args,\n","                            train_dataset=train,\n","                            eval_dataset=val,\n","                            data_collator=collator  # defines how to merge data into batches, using the collator function above\n","                            )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1yPQ40B1xhrU8uVhbj0lS-ynksGi7f2Sx"},"id":"IGyHLY640NRz","outputId":"8c0703e0-b806-4c49-ba6e-ba4215d88014","executionInfo":{"status":"ok","timestamp":1690847323418,"user_tz":360,"elapsed":27100887,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["from ray.tune.search.hyperopt import HyperOptSearch\n","from ray.tune.schedulers import ASHAScheduler\n","\n","best_run = trainer.hyperparameter_search(backend=\"ray\",\n","                                         resources_per_trial={\"gpu\": 1, \"cpu\": 0},\n","                                         n_trials=18,\n","                                         direction=\"maximize\",\n","                                         hp_space=my_hp_space_ray,\n","                                         search_alg=HyperOptSearch(metric='eval_micro_recall_no_o', mode=\"max\"),  #'eval_*f1_micro'\n","                                         scheduler=ASHAScheduler(metric='eval_micro_recall_no_o', mode=\"max\")\n","                                         )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zH0H8agAbzZi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690847323419,"user_tz":360,"elapsed":44,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"38a21950-d8bd-4b52-be51-47a22e3abec8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BestRun(run_id='6753986b', objective=8.574123831086196, hyperparameters={'learning_rate': 2.768901750544875e-05, 'num_train_epochs': 8, 'weight_decay': 0.0273138487143614, 'per_device_train_batch_size': 4})"]},"metadata":{},"execution_count":45}],"source":["best_run"]},{"cell_type":"markdown","metadata":{"id":"kv6pGzbGpv2D"},"source":["# Cossvalidation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhipElJSzRUF"},"outputs":[],"source":["#import tensorflow as tf\n","from torch.utils.data import DataLoader, ConcatDataset\n","from sklearn.model_selection import KFold\n","from torch import nn\n","from transformers import Trainer\n","\n","#print('GPU detected:', tf.config.list_physical_devices('GPU'))\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","results = np.zeros(5)\n","resultss = np.zeros(5)\n","dataset = ConcatDataset([train, test])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQyLOxyMjZq2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690976269366,"user_tz":360,"elapsed":19849183,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"9d036dcd-cb53-40e9-a051-90893463ea26"},"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8635\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17264\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17264' max='17264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17264/17264 1:04:04, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2158</td>\n","      <td>0.021000</td>\n","      <td>0.048026</td>\n","      <td>0.591558</td>\n","      <td>0.526223</td>\n","      <td>0.697114</td>\n","      <td>0.910806</td>\n","      <td>0.910806</td>\n","      <td>0.910806</td>\n","      <td>0.647785</td>\n","      <td>0.548724</td>\n","      <td>0.794764</td>\n","      <td>0.638010</td>\n","      <td>0.533251</td>\n","      <td>0.793991</td>\n","    </tr>\n","    <tr>\n","      <td>4316</td>\n","      <td>0.004800</td>\n","      <td>0.054148</td>\n","      <td>0.613942</td>\n","      <td>0.532669</td>\n","      <td>0.754255</td>\n","      <td>0.922837</td>\n","      <td>0.922837</td>\n","      <td>0.922837</td>\n","      <td>0.637092</td>\n","      <td>0.526964</td>\n","      <td>0.813532</td>\n","      <td>0.637986</td>\n","      <td>0.530488</td>\n","      <td>0.800123</td>\n","    </tr>\n","    <tr>\n","      <td>6474</td>\n","      <td>0.001300</td>\n","      <td>0.058260</td>\n","      <td>0.648107</td>\n","      <td>0.584845</td>\n","      <td>0.740460</td>\n","      <td>0.931833</td>\n","      <td>0.931833</td>\n","      <td>0.931833</td>\n","      <td>0.681218</td>\n","      <td>0.594595</td>\n","      <td>0.808510</td>\n","      <td>0.672121</td>\n","      <td>0.576409</td>\n","      <td>0.805947</td>\n","    </tr>\n","    <tr>\n","      <td>8632</td>\n","      <td>0.000500</td>\n","      <td>0.057363</td>\n","      <td>0.633148</td>\n","      <td>0.551276</td>\n","      <td>0.757556</td>\n","      <td>0.924383</td>\n","      <td>0.924383</td>\n","      <td>0.924383</td>\n","      <td>0.673833</td>\n","      <td>0.572419</td>\n","      <td>0.824106</td>\n","      <td>0.668635</td>\n","      <td>0.575215</td>\n","      <td>0.798283</td>\n","    </tr>\n","    <tr>\n","      <td>10790</td>\n","      <td>0.000100</td>\n","      <td>0.065241</td>\n","      <td>0.675597</td>\n","      <td>0.618340</td>\n","      <td>0.754879</td>\n","      <td>0.939819</td>\n","      <td>0.939819</td>\n","      <td>0.939819</td>\n","      <td>0.726075</td>\n","      <td>0.648785</td>\n","      <td>0.826741</td>\n","      <td>0.707467</td>\n","      <td>0.626003</td>\n","      <td>0.813305</td>\n","    </tr>\n","    <tr>\n","      <td>12948</td>\n","      <td>0.000200</td>\n","      <td>0.061650</td>\n","      <td>0.671331</td>\n","      <td>0.612664</td>\n","      <td>0.752944</td>\n","      <td>0.938332</td>\n","      <td>0.938332</td>\n","      <td>0.938332</td>\n","      <td>0.710284</td>\n","      <td>0.633775</td>\n","      <td>0.818980</td>\n","      <td>0.693427</td>\n","      <td>0.601668</td>\n","      <td>0.818210</td>\n","    </tr>\n","    <tr>\n","      <td>15106</td>\n","      <td>0.000100</td>\n","      <td>0.085389</td>\n","      <td>0.682484</td>\n","      <td>0.634577</td>\n","      <td>0.743883</td>\n","      <td>0.945172</td>\n","      <td>0.945172</td>\n","      <td>0.945172</td>\n","      <td>0.732688</td>\n","      <td>0.671449</td>\n","      <td>0.808696</td>\n","      <td>0.721918</td>\n","      <td>0.665288</td>\n","      <td>0.789086</td>\n","    </tr>\n","    <tr>\n","      <td>17264</td>\n","      <td>0.000000</td>\n","      <td>0.085574</td>\n","      <td>0.683822</td>\n","      <td>0.634926</td>\n","      <td>0.746845</td>\n","      <td>0.944979</td>\n","      <td>0.944979</td>\n","      <td>0.944979</td>\n","      <td>0.734107</td>\n","      <td>0.668296</td>\n","      <td>0.816928</td>\n","      <td>0.721684</td>\n","      <td>0.658081</td>\n","      <td>0.798896</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-2158\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-4316\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-6474\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-8632\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-10790\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-12948\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-15106\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-17264\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.68382229735842, 'eval_macro_precision': 0.6349262364698003, 'eval_macro_recall': 0.7468453400229537, 'eval_micro_f1': 0.9449789581691377, 'eval_micro_precision': 0.9449789581691377, 'eval_micro_recall': 0.9449789581691377, 'eval_macro_f1_no_o': 0.7341074407427798, 'eval_macro_precision_no_o': 0.6682963757547401, 'eval_macro_recall_no_o': 0.8169277556177517, 'eval_micro_f1_no_o': 0.7216837441152034, 'eval_micro_precision_no_o': 0.658080808080808, 'eval_micro_recall_no_o': 0.7988963825873697, 'eval_loss': 0.08557401420448488, 'eval_runtime': 38.1804, 'eval_samples_per_second': 14.117, 'eval_steps_per_second': 3.536, 'epoch': 8.0}\n","Accuracy for fold  0 :  0.7216837441152034  --  0.9449789581691377\n","--------------------------------\n","FOLD 1\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8635\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17264\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17264' max='17264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17264/17264 1:04:33, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2158</td>\n","      <td>0.013600</td>\n","      <td>0.006804</td>\n","      <td>0.778197</td>\n","      <td>0.724172</td>\n","      <td>0.861616</td>\n","      <td>0.960693</td>\n","      <td>0.960693</td>\n","      <td>0.960693</td>\n","      <td>0.800864</td>\n","      <td>0.760796</td>\n","      <td>0.871041</td>\n","      <td>0.795625</td>\n","      <td>0.707267</td>\n","      <td>0.909211</td>\n","    </tr>\n","    <tr>\n","      <td>4316</td>\n","      <td>0.002200</td>\n","      <td>0.009648</td>\n","      <td>0.778274</td>\n","      <td>0.717136</td>\n","      <td>0.885683</td>\n","      <td>0.960208</td>\n","      <td>0.960208</td>\n","      <td>0.960208</td>\n","      <td>0.825797</td>\n","      <td>0.785177</td>\n","      <td>0.885642</td>\n","      <td>0.813654</td>\n","      <td>0.733492</td>\n","      <td>0.913487</td>\n","    </tr>\n","    <tr>\n","      <td>6474</td>\n","      <td>0.000600</td>\n","      <td>0.007115</td>\n","      <td>0.805253</td>\n","      <td>0.759582</td>\n","      <td>0.877604</td>\n","      <td>0.966431</td>\n","      <td>0.966431</td>\n","      <td>0.966431</td>\n","      <td>0.839742</td>\n","      <td>0.804353</td>\n","      <td>0.890404</td>\n","      <td>0.833181</td>\n","      <td>0.777809</td>\n","      <td>0.897039</td>\n","    </tr>\n","    <tr>\n","      <td>8632</td>\n","      <td>0.000500</td>\n","      <td>0.009141</td>\n","      <td>0.778261</td>\n","      <td>0.696881</td>\n","      <td>0.895273</td>\n","      <td>0.958497</td>\n","      <td>0.958497</td>\n","      <td>0.958497</td>\n","      <td>0.809281</td>\n","      <td>0.727148</td>\n","      <td>0.913700</td>\n","      <td>0.809621</td>\n","      <td>0.726963</td>\n","      <td>0.913487</td>\n","    </tr>\n","    <tr>\n","      <td>10790</td>\n","      <td>0.000100</td>\n","      <td>0.009946</td>\n","      <td>0.822863</td>\n","      <td>0.779053</td>\n","      <td>0.885351</td>\n","      <td>0.971852</td>\n","      <td>0.971852</td>\n","      <td>0.971852</td>\n","      <td>0.848158</td>\n","      <td>0.780548</td>\n","      <td>0.930340</td>\n","      <td>0.845158</td>\n","      <td>0.771382</td>\n","      <td>0.934539</td>\n","    </tr>\n","    <tr>\n","      <td>12948</td>\n","      <td>0.000000</td>\n","      <td>0.008259</td>\n","      <td>0.845303</td>\n","      <td>0.808357</td>\n","      <td>0.891846</td>\n","      <td>0.976803</td>\n","      <td>0.976803</td>\n","      <td>0.976803</td>\n","      <td>0.868522</td>\n","      <td>0.823666</td>\n","      <td>0.920635</td>\n","      <td>0.870250</td>\n","      <td>0.820326</td>\n","      <td>0.926645</td>\n","    </tr>\n","    <tr>\n","      <td>15106</td>\n","      <td>0.000000</td>\n","      <td>0.009525</td>\n","      <td>0.846302</td>\n","      <td>0.809039</td>\n","      <td>0.894283</td>\n","      <td>0.976107</td>\n","      <td>0.976107</td>\n","      <td>0.976107</td>\n","      <td>0.867032</td>\n","      <td>0.817613</td>\n","      <td>0.925509</td>\n","      <td>0.865976</td>\n","      <td>0.806296</td>\n","      <td>0.935197</td>\n","    </tr>\n","    <tr>\n","      <td>17264</td>\n","      <td>0.000000</td>\n","      <td>0.009680</td>\n","      <td>0.849906</td>\n","      <td>0.819506</td>\n","      <td>0.889784</td>\n","      <td>0.977030</td>\n","      <td>0.977030</td>\n","      <td>0.977030</td>\n","      <td>0.869601</td>\n","      <td>0.828510</td>\n","      <td>0.917725</td>\n","      <td>0.868510</td>\n","      <td>0.814697</td>\n","      <td>0.929934</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-2158\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-4316\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-6474\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-8632\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-10790\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-12948\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-15106\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-17264\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.8499059708703517, 'eval_macro_precision': 0.8195059547011395, 'eval_macro_recall': 0.8897838726982823, 'eval_micro_f1': 0.9770304645387923, 'eval_micro_precision': 0.9770304645387923, 'eval_micro_recall': 0.9770304645387923, 'eval_macro_f1_no_o': 0.8696014595364613, 'eval_macro_precision_no_o': 0.828509734207192, 'eval_macro_recall_no_o': 0.9177245728313385, 'eval_micro_f1_no_o': 0.8685099846390169, 'eval_micro_precision_no_o': 0.8146974063400576, 'eval_micro_recall_no_o': 0.9299342105263158, 'eval_loss': 0.009679842092705516, 'eval_runtime': 38.7036, 'eval_samples_per_second': 13.926, 'eval_steps_per_second': 3.488, 'epoch': 8.0}\n","Accuracy for fold  1 :  0.8685099846390169  --  0.9770304645387923\n","--------------------------------\n","FOLD 2\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8635\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17264\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17264' max='17264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17264/17264 1:04:28, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2158</td>\n","      <td>0.001400</td>\n","      <td>0.002259</td>\n","      <td>0.863730</td>\n","      <td>0.801384</td>\n","      <td>0.942543</td>\n","      <td>0.974025</td>\n","      <td>0.974025</td>\n","      <td>0.974025</td>\n","      <td>0.869361</td>\n","      <td>0.803930</td>\n","      <td>0.948614</td>\n","      <td>0.867719</td>\n","      <td>0.795233</td>\n","      <td>0.954745</td>\n","    </tr>\n","    <tr>\n","      <td>4316</td>\n","      <td>0.001600</td>\n","      <td>0.004520</td>\n","      <td>0.842399</td>\n","      <td>0.771521</td>\n","      <td>0.937936</td>\n","      <td>0.969706</td>\n","      <td>0.969706</td>\n","      <td>0.969706</td>\n","      <td>0.851656</td>\n","      <td>0.791580</td>\n","      <td>0.924952</td>\n","      <td>0.866896</td>\n","      <td>0.820052</td>\n","      <td>0.919416</td>\n","    </tr>\n","    <tr>\n","      <td>6474</td>\n","      <td>0.000100</td>\n","      <td>0.002428</td>\n","      <td>0.875122</td>\n","      <td>0.818443</td>\n","      <td>0.954041</td>\n","      <td>0.976900</td>\n","      <td>0.976900</td>\n","      <td>0.976900</td>\n","      <td>0.895917</td>\n","      <td>0.843233</td>\n","      <td>0.959112</td>\n","      <td>0.889311</td>\n","      <td>0.831386</td>\n","      <td>0.955912</td>\n","    </tr>\n","    <tr>\n","      <td>8632</td>\n","      <td>0.000200</td>\n","      <td>0.002694</td>\n","      <td>0.848616</td>\n","      <td>0.767427</td>\n","      <td>0.962337</td>\n","      <td>0.968366</td>\n","      <td>0.968366</td>\n","      <td>0.968366</td>\n","      <td>0.875793</td>\n","      <td>0.800147</td>\n","      <td>0.967710</td>\n","      <td>0.871680</td>\n","      <td>0.796234</td>\n","      <td>0.962920</td>\n","    </tr>\n","    <tr>\n","      <td>10790</td>\n","      <td>0.000000</td>\n","      <td>0.001792</td>\n","      <td>0.884954</td>\n","      <td>0.830194</td>\n","      <td>0.953999</td>\n","      <td>0.975917</td>\n","      <td>0.975917</td>\n","      <td>0.975917</td>\n","      <td>0.878932</td>\n","      <td>0.813465</td>\n","      <td>0.962255</td>\n","      <td>0.868753</td>\n","      <td>0.790380</td>\n","      <td>0.964380</td>\n","    </tr>\n","    <tr>\n","      <td>12948</td>\n","      <td>0.000000</td>\n","      <td>0.002026</td>\n","      <td>0.909494</td>\n","      <td>0.861160</td>\n","      <td>0.968779</td>\n","      <td>0.982619</td>\n","      <td>0.982619</td>\n","      <td>0.982619</td>\n","      <td>0.915465</td>\n","      <td>0.870835</td>\n","      <td>0.966265</td>\n","      <td>0.913188</td>\n","      <td>0.867157</td>\n","      <td>0.964380</td>\n","    </tr>\n","    <tr>\n","      <td>15106</td>\n","      <td>0.000000</td>\n","      <td>0.001867</td>\n","      <td>0.906923</td>\n","      <td>0.857926</td>\n","      <td>0.967983</td>\n","      <td>0.982813</td>\n","      <td>0.982813</td>\n","      <td>0.982813</td>\n","      <td>0.916523</td>\n","      <td>0.874427</td>\n","      <td>0.964145</td>\n","      <td>0.914127</td>\n","      <td>0.869565</td>\n","      <td>0.963504</td>\n","    </tr>\n","    <tr>\n","      <td>17264</td>\n","      <td>0.000000</td>\n","      <td>0.002005</td>\n","      <td>0.905749</td>\n","      <td>0.858725</td>\n","      <td>0.963602</td>\n","      <td>0.983140</td>\n","      <td>0.983140</td>\n","      <td>0.983140</td>\n","      <td>0.917760</td>\n","      <td>0.877605</td>\n","      <td>0.962971</td>\n","      <td>0.916122</td>\n","      <td>0.874867</td>\n","      <td>0.961460</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-2158\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-4316\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-6474\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-8632\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-10790\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-12948\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-15106\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-17264\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9057493052279941, 'eval_macro_precision': 0.8587248538471226, 'eval_macro_recall': 0.9636023355513034, 'eval_micro_f1': 0.983140210300557, 'eval_micro_precision': 0.983140210300557, 'eval_micro_recall': 0.983140210300557, 'eval_macro_f1_no_o': 0.9177595828113452, 'eval_macro_precision_no_o': 0.8776051012341091, 'eval_macro_recall_no_o': 0.9629705476903819, 'eval_micro_f1_no_o': 0.9161218528307136, 'eval_micro_precision_no_o': 0.8748671625929861, 'eval_micro_recall_no_o': 0.9614598540145985, 'eval_loss': 0.0020051236908271066, 'eval_runtime': 38.7185, 'eval_samples_per_second': 13.921, 'eval_steps_per_second': 3.487, 'epoch': 8.0}\n","Accuracy for fold  2 :  0.9161218528307136  --  0.983140210300557\n","--------------------------------\n","FOLD 3\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8635\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17264\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17264' max='17264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17264/17264 1:04:31, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2158</td>\n","      <td>0.000200</td>\n","      <td>0.001002</td>\n","      <td>0.921811</td>\n","      <td>0.887600</td>\n","      <td>0.965460</td>\n","      <td>0.982832</td>\n","      <td>0.982832</td>\n","      <td>0.982832</td>\n","      <td>0.939380</td>\n","      <td>0.908957</td>\n","      <td>0.973180</td>\n","      <td>0.929973</td>\n","      <td>0.888858</td>\n","      <td>0.975075</td>\n","    </tr>\n","    <tr>\n","      <td>4316</td>\n","      <td>0.000100</td>\n","      <td>0.001436</td>\n","      <td>0.921591</td>\n","      <td>0.880857</td>\n","      <td>0.970719</td>\n","      <td>0.985411</td>\n","      <td>0.985411</td>\n","      <td>0.985411</td>\n","      <td>0.936701</td>\n","      <td>0.908017</td>\n","      <td>0.967712</td>\n","      <td>0.935605</td>\n","      <td>0.901001</td>\n","      <td>0.972973</td>\n","    </tr>\n","    <tr>\n","      <td>6474</td>\n","      <td>0.000100</td>\n","      <td>0.003099</td>\n","      <td>0.910001</td>\n","      <td>0.897772</td>\n","      <td>0.930239</td>\n","      <td>0.983852</td>\n","      <td>0.983852</td>\n","      <td>0.983852</td>\n","      <td>0.916618</td>\n","      <td>0.881849</td>\n","      <td>0.961245</td>\n","      <td>0.903525</td>\n","      <td>0.848589</td>\n","      <td>0.966066</td>\n","    </tr>\n","    <tr>\n","      <td>8632</td>\n","      <td>0.000000</td>\n","      <td>0.001043</td>\n","      <td>0.924860</td>\n","      <td>0.884117</td>\n","      <td>0.971028</td>\n","      <td>0.984482</td>\n","      <td>0.984482</td>\n","      <td>0.984482</td>\n","      <td>0.927820</td>\n","      <td>0.880159</td>\n","      <td>0.981162</td>\n","      <td>0.920532</td>\n","      <td>0.869856</td>\n","      <td>0.977477</td>\n","    </tr>\n","    <tr>\n","      <td>10790</td>\n","      <td>0.000300</td>\n","      <td>0.001732</td>\n","      <td>0.888404</td>\n","      <td>0.850274</td>\n","      <td>0.941716</td>\n","      <td>0.980763</td>\n","      <td>0.980763</td>\n","      <td>0.980763</td>\n","      <td>0.862575</td>\n","      <td>0.809018</td>\n","      <td>0.942358</td>\n","      <td>0.881936</td>\n","      <td>0.821290</td>\n","      <td>0.952252</td>\n","    </tr>\n","    <tr>\n","      <td>12948</td>\n","      <td>0.000000</td>\n","      <td>0.001272</td>\n","      <td>0.925486</td>\n","      <td>0.887161</td>\n","      <td>0.969821</td>\n","      <td>0.986551</td>\n","      <td>0.986551</td>\n","      <td>0.986551</td>\n","      <td>0.932058</td>\n","      <td>0.896849</td>\n","      <td>0.970792</td>\n","      <td>0.929415</td>\n","      <td>0.893134</td>\n","      <td>0.968769</td>\n","    </tr>\n","    <tr>\n","      <td>15106</td>\n","      <td>0.000000</td>\n","      <td>0.000886</td>\n","      <td>0.924921</td>\n","      <td>0.881139</td>\n","      <td>0.975718</td>\n","      <td>0.983777</td>\n","      <td>0.983777</td>\n","      <td>0.983777</td>\n","      <td>0.922478</td>\n","      <td>0.869765</td>\n","      <td>0.982956</td>\n","      <td>0.914030</td>\n","      <td>0.856243</td>\n","      <td>0.980180</td>\n","    </tr>\n","    <tr>\n","      <td>17264</td>\n","      <td>0.000000</td>\n","      <td>0.000804</td>\n","      <td>0.927088</td>\n","      <td>0.885201</td>\n","      <td>0.975160</td>\n","      <td>0.985006</td>\n","      <td>0.985006</td>\n","      <td>0.985006</td>\n","      <td>0.926855</td>\n","      <td>0.878070</td>\n","      <td>0.982280</td>\n","      <td>0.919048</td>\n","      <td>0.865094</td>\n","      <td>0.980180</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-2158\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-4316\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-6474\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-8632\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-10790\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-12948\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-15106\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-17264\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9270876710376388, 'eval_macro_precision': 0.8852010120508429, 'eval_macro_recall': 0.9751601754360164, 'eval_micro_f1': 0.985006372291776, 'eval_micro_precision': 0.985006372291776, 'eval_micro_recall': 0.985006372291776, 'eval_macro_f1_no_o': 0.926855376855895, 'eval_macro_precision_no_o': 0.8780704426137423, 'eval_macro_recall_no_o': 0.9822799509922172, 'eval_micro_f1_no_o': 0.9190482894551598, 'eval_micro_precision_no_o': 0.8650940895838855, 'eval_micro_recall_no_o': 0.9801801801801802, 'eval_loss': 0.0008043160018255715, 'eval_runtime': 38.2636, 'eval_samples_per_second': 14.087, 'eval_steps_per_second': 3.528, 'epoch': 8.0}\n","Accuracy for fold  3 :  0.9190482894551598  --  0.985006372291776\n","--------------------------------\n","FOLD 4\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8636\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17272\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17272' max='17272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17272/17272 1:04:27, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2159</td>\n","      <td>0.000400</td>\n","      <td>0.000896</td>\n","      <td>0.907424</td>\n","      <td>0.859130</td>\n","      <td>0.973694</td>\n","      <td>0.983011</td>\n","      <td>0.983011</td>\n","      <td>0.983011</td>\n","      <td>0.928092</td>\n","      <td>0.897422</td>\n","      <td>0.965483</td>\n","      <td>0.916303</td>\n","      <td>0.864072</td>\n","      <td>0.975255</td>\n","    </tr>\n","    <tr>\n","      <td>4318</td>\n","      <td>0.000200</td>\n","      <td>0.000847</td>\n","      <td>0.910348</td>\n","      <td>0.869868</td>\n","      <td>0.957323</td>\n","      <td>0.982341</td>\n","      <td>0.982341</td>\n","      <td>0.982341</td>\n","      <td>0.917628</td>\n","      <td>0.873167</td>\n","      <td>0.969366</td>\n","      <td>0.904941</td>\n","      <td>0.849011</td>\n","      <td>0.968760</td>\n","    </tr>\n","    <tr>\n","      <td>6477</td>\n","      <td>0.000100</td>\n","      <td>0.000525</td>\n","      <td>0.917922</td>\n","      <td>0.876368</td>\n","      <td>0.968853</td>\n","      <td>0.985632</td>\n","      <td>0.985632</td>\n","      <td>0.985632</td>\n","      <td>0.941752</td>\n","      <td>0.917937</td>\n","      <td>0.967662</td>\n","      <td>0.941740</td>\n","      <td>0.912892</td>\n","      <td>0.972471</td>\n","    </tr>\n","    <tr>\n","      <td>8636</td>\n","      <td>0.000000</td>\n","      <td>0.001125</td>\n","      <td>0.923948</td>\n","      <td>0.878928</td>\n","      <td>0.979504</td>\n","      <td>0.986135</td>\n","      <td>0.986135</td>\n","      <td>0.986135</td>\n","      <td>0.938903</td>\n","      <td>0.904084</td>\n","      <td>0.977633</td>\n","      <td>0.937361</td>\n","      <td>0.899148</td>\n","      <td>0.978967</td>\n","    </tr>\n","    <tr>\n","      <td>10795</td>\n","      <td>0.000000</td>\n","      <td>0.002436</td>\n","      <td>0.927682</td>\n","      <td>0.910104</td>\n","      <td>0.949340</td>\n","      <td>0.987019</td>\n","      <td>0.987019</td>\n","      <td>0.987019</td>\n","      <td>0.934915</td>\n","      <td>0.915150</td>\n","      <td>0.959496</td>\n","      <td>0.930983</td>\n","      <td>0.893151</td>\n","      <td>0.972162</td>\n","    </tr>\n","    <tr>\n","      <td>12954</td>\n","      <td>0.000000</td>\n","      <td>0.001333</td>\n","      <td>0.928496</td>\n","      <td>0.889431</td>\n","      <td>0.976013</td>\n","      <td>0.987323</td>\n","      <td>0.987323</td>\n","      <td>0.987323</td>\n","      <td>0.947942</td>\n","      <td>0.922631</td>\n","      <td>0.975813</td>\n","      <td>0.946095</td>\n","      <td>0.914550</td>\n","      <td>0.979895</td>\n","    </tr>\n","    <tr>\n","      <td>15113</td>\n","      <td>0.000000</td>\n","      <td>0.000666</td>\n","      <td>0.935669</td>\n","      <td>0.901066</td>\n","      <td>0.976305</td>\n","      <td>0.988512</td>\n","      <td>0.988512</td>\n","      <td>0.988512</td>\n","      <td>0.948950</td>\n","      <td>0.923978</td>\n","      <td>0.976206</td>\n","      <td>0.945938</td>\n","      <td>0.914525</td>\n","      <td>0.979586</td>\n","    </tr>\n","    <tr>\n","      <td>17272</td>\n","      <td>0.000000</td>\n","      <td>0.000706</td>\n","      <td>0.934667</td>\n","      <td>0.898837</td>\n","      <td>0.977089</td>\n","      <td>0.988664</td>\n","      <td>0.988664</td>\n","      <td>0.988664</td>\n","      <td>0.950070</td>\n","      <td>0.924929</td>\n","      <td>0.977415</td>\n","      <td>0.947825</td>\n","      <td>0.917245</td>\n","      <td>0.980513</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-2159\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-4318\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-6477\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-8636\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-10795\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-12954\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-15113\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-17272\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished. Saving trained model.\n","Starting testing\n","{'eval_macro_f1': 0.9346671724293613, 'eval_macro_precision': 0.8988368779239028, 'eval_macro_recall': 0.9770894607265225, 'eval_micro_f1': 0.9886640663091175, 'eval_micro_precision': 0.9886640663091175, 'eval_micro_recall': 0.9886640663091175, 'eval_macro_f1_no_o': 0.9500701375534556, 'eval_macro_precision_no_o': 0.9249287157628564, 'eval_macro_recall_no_o': 0.9774146467304248, 'eval_micro_f1_no_o': 0.9478247869636717, 'eval_micro_precision_no_o': 0.9172453703703703, 'eval_micro_recall_no_o': 0.9805134549953604, 'eval_loss': 0.000706205445108781, 'eval_runtime': 38.391, 'eval_samples_per_second': 14.04, 'eval_steps_per_second': 3.516, 'epoch': 8.0}\n","Accuracy for fold  4 :  0.9478247869636717  --  0.9886640663091175\n","--------------------------------\n"]}],"source":["for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n","\n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","\n","    # Sample elements randomly from a given list of ids, no replacement.\n","    #train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    #test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","\n","    local_train = []\n","    i = 0\n","    for idx in train_ids:\n","      #if i <= 1920:\n","      local_train.append(dataset[idx])\n","      #i += 1\n","\n","    local_test = []\n","    i = 0\n","    for idx in test_ids:\n","      #if i <= 480:\n","      local_test.append(dataset[idx])\n","      #i += 1\n","\n","    training_args = TrainingArguments(\"trained_scibert_ner_model\", # output dir\n","                                      learning_rate=2.768901750544875e-05,\n","                                      weight_decay=0.0273138487143614,\n","                                      num_train_epochs=8,\n","                                      dataloader_drop_last=True,\n","                                      per_device_eval_batch_size=4,\n","                                      per_device_train_batch_size=4,\n","                                      logging_steps=50,\n","                                      save_steps=len(local_train) // batch_size,\n","                                      lr_scheduler_type='cosine',\n","                                      evaluation_strategy='steps',\n","                                      eval_steps=len(local_train) // batch_size\n","                                      )\n","\n","    #learning_rate 1.5441110254159498e-05\n","    #num_train_epochs 12\n","    #weight_decay 0.21467682833420043\n","    #per_device_train_batch_size 16\n","\n","\n","    # Init the neural network\n","    ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","    ner_model.sci_embeddings.requires_grad = False\n","\n","    trainer = MultilabelTrainer(model=ner_model,\n","                                args=training_args,\n","                                train_dataset=local_train,\n","                                eval_dataset=local_test,\n","                                data_collator=collator  # defines how to merge data into batches, using the collator function above\n","                                )\n","\n","    #Loading Best parameters\n","    #load_param()\n","\n","    #Training\n","    trainer.train()\n","\n","    # Process is complete.\n","    print('Training process has finished. Saving trained model.')\n","\n","    # Print about testing\n","    print('Starting testing')\n","\n","    # Saving the model\n","    save_path = f'./model-fold-{fold}.pth'\n","    torch.save(ner_model.state_dict(), save_path)\n","\n","    # Evaluationfor this fold\n","    #correct, total = 0, 0\n","    with torch.no_grad():\n","      result = trainer.evaluate(local_test)\n","      print(result)\n","\n","      # Print accuracy\n","      print('Accuracy for fold ', fold, ': ', result['eval_micro_f1_no_o'], ' -- ', result['eval_micro_f1'])\n","      print('--------------------------------')\n","      results[fold] = result['eval_micro_f1_no_o']\n","      resultss[fold] = result['eval_micro_f1']\n","      del result\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BBA4owXH8oS1"},"source":["# Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dhusoblW-oCA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690976269367,"user_tz":360,"elapsed":40,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"3318abd4-2424-4ff4-e0fe-1bb730464a06"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.72168374, 0.86850998, 0.91612185, 0.91904829, 0.94782479])"]},"metadata":{},"execution_count":45}],"source":["results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ryi6TlOOQaTE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690976269367,"user_tz":360,"elapsed":6,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"a608c39d-67d1-43cd-82e8-fe9ac007630d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.94497896, 0.97703046, 0.98314021, 0.98500637, 0.98866407])"]},"metadata":{},"execution_count":46}],"source":["resultss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yPIH-gt_-foF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690976269368,"user_tz":360,"elapsed":7,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"682f4794-9a9b-4a9e-f759-c9e4439f1363"},"outputs":[{"output_type":"stream","name":"stdout","text":["K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n","--------------------------------\n","Fold 0: 0.7216837441152034 %\n","Fold 1: 0.8685099846390169 %\n","Fold 2: 0.9161218528307136 %\n","Fold 3: 0.9190482894551598 %\n","Fold 4: 0.9478247869636717 %\n","Average: 0.874637731600753 %\n"]}],"source":["# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","key = 0\n","for value in results:\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","  key += 1\n","print(f'Average: {sum/len(results)} %')"]},{"cell_type":"markdown","metadata":{"id":"1DkDHptAhniL"},"source":["# Pytorch Training - Loop UPDT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rirS-e83GVn0"},"outputs":[],"source":["device = 'cuda'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSDdzo_so0vk"},"outputs":[],"source":["training_args = TrainingArguments(\"trained_scibert_ner_model\", # output dir\n","                                      learning_rate=2.768901750544875e-05,\n","                                      weight_decay=0.0273138487143614,\n","                                      num_train_epochs=8,\n","                                      dataloader_drop_last=True,\n","                                      per_device_eval_batch_size=4,\n","                                      per_device_train_batch_size=4,\n","                                      logging_steps=50,\n","                                      save_steps=len(train) // batch_size,\n","                                      lr_scheduler_type='cosine',\n","                                      evaluation_strategy='steps',\n","                                      eval_steps=len(train) // batch_size,\n","                                      report_to='all'\n","                                      )\n","\n","#learning_rate 1.5441110254159498e-05\n","#num_train_epochs 12\n","#weight_decay 0.21467682833420043\n","#per_device_train_batch_size 16\n","\n","#load_param()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nZR3aDuKyUqy","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"74c73843-08c8-479e-d2fd-a76a2eaf6021","executionInfo":{"status":"ok","timestamp":1691011783496,"user_tz":360,"elapsed":16715853,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8816\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17632\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train run #0\n","--------------------------------\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3484' max='17632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 3484/17632 13:46 < 55:57, 4.21 it/s, Epoch 1.58/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2204</td>\n","      <td>0.016100</td>\n","      <td>0.054301</td>\n","      <td>0.581655</td>\n","      <td>0.499412</td>\n","      <td>0.724854</td>\n","      <td>0.886183</td>\n","      <td>0.886183</td>\n","      <td>0.886183</td>\n","      <td>0.618525</td>\n","      <td>0.519438</td>\n","      <td>0.767768</td>\n","      <td>0.620675</td>\n","      <td>0.514202</td>\n","      <td>0.782758</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-2204\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17632' max='17632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17632/17632 1:12:30, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2204</td>\n","      <td>0.016100</td>\n","      <td>0.054301</td>\n","      <td>0.581655</td>\n","      <td>0.499412</td>\n","      <td>0.724854</td>\n","      <td>0.886183</td>\n","      <td>0.886183</td>\n","      <td>0.886183</td>\n","      <td>0.618525</td>\n","      <td>0.519438</td>\n","      <td>0.767768</td>\n","      <td>0.620675</td>\n","      <td>0.514202</td>\n","      <td>0.782758</td>\n","    </tr>\n","    <tr>\n","      <td>4408</td>\n","      <td>0.003200</td>\n","      <td>0.061881</td>\n","      <td>0.611389</td>\n","      <td>0.535692</td>\n","      <td>0.739636</td>\n","      <td>0.900365</td>\n","      <td>0.900365</td>\n","      <td>0.900365</td>\n","      <td>0.653316</td>\n","      <td>0.565506</td>\n","      <td>0.777773</td>\n","      <td>0.645373</td>\n","      <td>0.551505</td>\n","      <td>0.777748</td>\n","    </tr>\n","    <tr>\n","      <td>6612</td>\n","      <td>0.011300</td>\n","      <td>0.081936</td>\n","      <td>0.642563</td>\n","      <td>0.607479</td>\n","      <td>0.691803</td>\n","      <td>0.918235</td>\n","      <td>0.918235</td>\n","      <td>0.918235</td>\n","      <td>0.668394</td>\n","      <td>0.636288</td>\n","      <td>0.716518</td>\n","      <td>0.647776</td>\n","      <td>0.578871</td>\n","      <td>0.735302</td>\n","    </tr>\n","    <tr>\n","      <td>8816</td>\n","      <td>0.000500</td>\n","      <td>0.086232</td>\n","      <td>0.634516</td>\n","      <td>0.580115</td>\n","      <td>0.718082</td>\n","      <td>0.915955</td>\n","      <td>0.915955</td>\n","      <td>0.915955</td>\n","      <td>0.673809</td>\n","      <td>0.616821</td>\n","      <td>0.749274</td>\n","      <td>0.665255</td>\n","      <td>0.600722</td>\n","      <td>0.745320</td>\n","    </tr>\n","    <tr>\n","      <td>11020</td>\n","      <td>0.000100</td>\n","      <td>0.080817</td>\n","      <td>0.659047</td>\n","      <td>0.604527</td>\n","      <td>0.736668</td>\n","      <td>0.922052</td>\n","      <td>0.922052</td>\n","      <td>0.922052</td>\n","      <td>0.680355</td>\n","      <td>0.603674</td>\n","      <td>0.782386</td>\n","      <td>0.673119</td>\n","      <td>0.592385</td>\n","      <td>0.779330</td>\n","    </tr>\n","    <tr>\n","      <td>13224</td>\n","      <td>0.000400</td>\n","      <td>0.082161</td>\n","      <td>0.657853</td>\n","      <td>0.591638</td>\n","      <td>0.759868</td>\n","      <td>0.913772</td>\n","      <td>0.913772</td>\n","      <td>0.913772</td>\n","      <td>0.688081</td>\n","      <td>0.611719</td>\n","      <td>0.790673</td>\n","      <td>0.677800</td>\n","      <td>0.595528</td>\n","      <td>0.786449</td>\n","    </tr>\n","    <tr>\n","      <td>15428</td>\n","      <td>0.000000</td>\n","      <td>0.103284</td>\n","      <td>0.671359</td>\n","      <td>0.624551</td>\n","      <td>0.734502</td>\n","      <td>0.926564</td>\n","      <td>0.926564</td>\n","      <td>0.926564</td>\n","      <td>0.701223</td>\n","      <td>0.654301</td>\n","      <td>0.758283</td>\n","      <td>0.693414</td>\n","      <td>0.640116</td>\n","      <td>0.756393</td>\n","    </tr>\n","    <tr>\n","      <td>17632</td>\n","      <td>0.000000</td>\n","      <td>0.104851</td>\n","      <td>0.673620</td>\n","      <td>0.628488</td>\n","      <td>0.735008</td>\n","      <td>0.927421</td>\n","      <td>0.927421</td>\n","      <td>0.927421</td>\n","      <td>0.703511</td>\n","      <td>0.656722</td>\n","      <td>0.760267</td>\n","      <td>0.695747</td>\n","      <td>0.642204</td>\n","      <td>0.759030</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-4408\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-6612\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-8816\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-11020\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-13224\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-15428\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-17632\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8816\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17632\n"]},{"output_type":"stream","name":"stdout","text":["{'eval_macro_f1': 0.6736201515697119, 'eval_macro_precision': 0.6284882899480777, 'eval_macro_recall': 0.7350081379774406, 'eval_micro_f1': 0.9274209198525131, 'eval_micro_precision': 0.9274209198525131, 'eval_micro_recall': 0.9274209198525131, 'eval_macro_f1_no_o': 0.7035105378375696, 'eval_macro_precision_no_o': 0.6567224837784783, 'eval_macro_recall_no_o': 0.7602673893804481, 'eval_micro_f1_no_o': 0.6957467375543742, 'eval_micro_precision_no_o': 0.6422038813294669, 'eval_micro_recall_no_o': 0.7590297917215925, 'eval_loss': 0.10485096109724627, 'eval_runtime': 42.7274, 'eval_samples_per_second': 11.562, 'eval_steps_per_second': 2.902, 'epoch': 8.0}\n","Accuracy for fold  0 :  0.6957467375543742  --  0.9274209198525131\n","--------------------------------\n","Testing process has finished.\n","Train run #1\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17632' max='17632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17632/17632 1:12:12, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2204</td>\n","      <td>0.002200</td>\n","      <td>0.151800</td>\n","      <td>0.643231</td>\n","      <td>0.628174</td>\n","      <td>0.670913</td>\n","      <td>0.919561</td>\n","      <td>0.919561</td>\n","      <td>0.919561</td>\n","      <td>0.648599</td>\n","      <td>0.662318</td>\n","      <td>0.640940</td>\n","      <td>0.653681</td>\n","      <td>0.644063</td>\n","      <td>0.663591</td>\n","    </tr>\n","    <tr>\n","      <td>4408</td>\n","      <td>0.000200</td>\n","      <td>0.102756</td>\n","      <td>0.635114</td>\n","      <td>0.576166</td>\n","      <td>0.739542</td>\n","      <td>0.908063</td>\n","      <td>0.908063</td>\n","      <td>0.908063</td>\n","      <td>0.628505</td>\n","      <td>0.571560</td>\n","      <td>0.742446</td>\n","      <td>0.627855</td>\n","      <td>0.541818</td>\n","      <td>0.746375</td>\n","    </tr>\n","    <tr>\n","      <td>6612</td>\n","      <td>0.001200</td>\n","      <td>0.134172</td>\n","      <td>0.645789</td>\n","      <td>0.621591</td>\n","      <td>0.685723</td>\n","      <td>0.922440</td>\n","      <td>0.922440</td>\n","      <td>0.922440</td>\n","      <td>0.664054</td>\n","      <td>0.634817</td>\n","      <td>0.705699</td>\n","      <td>0.647750</td>\n","      <td>0.589201</td>\n","      <td>0.719220</td>\n","    </tr>\n","    <tr>\n","      <td>8816</td>\n","      <td>0.000200</td>\n","      <td>0.117387</td>\n","      <td>0.655598</td>\n","      <td>0.597697</td>\n","      <td>0.744318</td>\n","      <td>0.917039</td>\n","      <td>0.917039</td>\n","      <td>0.917039</td>\n","      <td>0.669762</td>\n","      <td>0.609436</td>\n","      <td>0.754355</td>\n","      <td>0.651399</td>\n","      <td>0.569316</td>\n","      <td>0.761139</td>\n","    </tr>\n","    <tr>\n","      <td>11020</td>\n","      <td>0.000000</td>\n","      <td>0.121730</td>\n","      <td>0.665026</td>\n","      <td>0.613717</td>\n","      <td>0.735229</td>\n","      <td>0.922278</td>\n","      <td>0.922278</td>\n","      <td>0.922278</td>\n","      <td>0.679338</td>\n","      <td>0.621971</td>\n","      <td>0.759504</td>\n","      <td>0.668127</td>\n","      <td>0.593609</td>\n","      <td>0.764039</td>\n","    </tr>\n","    <tr>\n","      <td>13224</td>\n","      <td>0.000000</td>\n","      <td>0.136938</td>\n","      <td>0.676760</td>\n","      <td>0.639702</td>\n","      <td>0.729944</td>\n","      <td>0.927049</td>\n","      <td>0.927049</td>\n","      <td>0.927049</td>\n","      <td>0.693295</td>\n","      <td>0.669931</td>\n","      <td>0.733079</td>\n","      <td>0.680193</td>\n","      <td>0.640793</td>\n","      <td>0.724756</td>\n","    </tr>\n","    <tr>\n","      <td>15428</td>\n","      <td>0.000000</td>\n","      <td>0.140423</td>\n","      <td>0.679429</td>\n","      <td>0.639184</td>\n","      <td>0.734562</td>\n","      <td>0.928116</td>\n","      <td>0.928116</td>\n","      <td>0.928116</td>\n","      <td>0.703777</td>\n","      <td>0.669690</td>\n","      <td>0.751434</td>\n","      <td>0.688505</td>\n","      <td>0.635714</td>\n","      <td>0.750857</td>\n","    </tr>\n","    <tr>\n","      <td>17632</td>\n","      <td>0.000000</td>\n","      <td>0.143935</td>\n","      <td>0.680463</td>\n","      <td>0.639980</td>\n","      <td>0.734161</td>\n","      <td>0.929022</td>\n","      <td>0.929022</td>\n","      <td>0.929022</td>\n","      <td>0.704859</td>\n","      <td>0.669849</td>\n","      <td>0.750281</td>\n","      <td>0.690168</td>\n","      <td>0.642225</td>\n","      <td>0.745848</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-2204\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-4408\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-6612\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-8816\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-11020\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-13224\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-15428\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-17632\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6804631619612505, 'eval_macro_precision': 0.6399796126674588, 'eval_macro_recall': 0.7341613643716897, 'eval_micro_f1': 0.9290219289734135, 'eval_micro_precision': 0.9290219289734135, 'eval_micro_recall': 0.9290219289734135, 'eval_macro_f1_no_o': 0.7048585035833587, 'eval_macro_precision_no_o': 0.6698494886835386, 'eval_macro_recall_no_o': 0.7502807147673861, 'eval_micro_f1_no_o': 0.6901683337399365, 'eval_micro_precision_no_o': 0.6422247446083995, 'eval_micro_recall_no_o': 0.7458476140258371, 'eval_loss': 0.14393493550453515, 'eval_runtime': 42.3863, 'eval_samples_per_second': 11.655, 'eval_steps_per_second': 2.925, 'epoch': 8.0}\n","Accuracy for fold  1 :  0.6901683337399365  --  0.9290219289734135\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8816\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17632\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #2\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17632' max='17632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17632/17632 1:12:15, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2204</td>\n","      <td>0.000300</td>\n","      <td>0.150644</td>\n","      <td>0.610745</td>\n","      <td>0.529042</td>\n","      <td>0.756876</td>\n","      <td>0.898506</td>\n","      <td>0.898506</td>\n","      <td>0.898506</td>\n","      <td>0.644539</td>\n","      <td>0.550661</td>\n","      <td>0.782594</td>\n","      <td>0.637646</td>\n","      <td>0.550844</td>\n","      <td>0.756921</td>\n","    </tr>\n","    <tr>\n","      <td>4408</td>\n","      <td>0.003300</td>\n","      <td>0.133447</td>\n","      <td>0.625881</td>\n","      <td>0.578919</td>\n","      <td>0.694694</td>\n","      <td>0.912219</td>\n","      <td>0.912219</td>\n","      <td>0.912219</td>\n","      <td>0.643890</td>\n","      <td>0.582005</td>\n","      <td>0.730371</td>\n","      <td>0.637373</td>\n","      <td>0.567662</td>\n","      <td>0.726602</td>\n","    </tr>\n","    <tr>\n","      <td>6612</td>\n","      <td>0.000700</td>\n","      <td>0.133917</td>\n","      <td>0.641113</td>\n","      <td>0.598724</td>\n","      <td>0.705858</td>\n","      <td>0.915858</td>\n","      <td>0.915858</td>\n","      <td>0.915858</td>\n","      <td>0.669229</td>\n","      <td>0.648555</td>\n","      <td>0.701689</td>\n","      <td>0.653837</td>\n","      <td>0.610997</td>\n","      <td>0.703137</td>\n","    </tr>\n","    <tr>\n","      <td>8816</td>\n","      <td>0.000100</td>\n","      <td>0.129453</td>\n","      <td>0.652526</td>\n","      <td>0.588928</td>\n","      <td>0.752460</td>\n","      <td>0.917944</td>\n","      <td>0.917944</td>\n","      <td>0.917944</td>\n","      <td>0.676640</td>\n","      <td>0.606217</td>\n","      <td>0.768219</td>\n","      <td>0.670885</td>\n","      <td>0.603754</td>\n","      <td>0.754811</td>\n","    </tr>\n","    <tr>\n","      <td>11020</td>\n","      <td>0.000000</td>\n","      <td>0.144468</td>\n","      <td>0.665251</td>\n","      <td>0.610942</td>\n","      <td>0.740600</td>\n","      <td>0.923831</td>\n","      <td>0.923831</td>\n","      <td>0.923831</td>\n","      <td>0.682232</td>\n","      <td>0.632143</td>\n","      <td>0.743667</td>\n","      <td>0.678769</td>\n","      <td>0.623867</td>\n","      <td>0.744266</td>\n","    </tr>\n","    <tr>\n","      <td>13224</td>\n","      <td>0.000000</td>\n","      <td>0.163178</td>\n","      <td>0.675312</td>\n","      <td>0.623530</td>\n","      <td>0.743140</td>\n","      <td>0.927033</td>\n","      <td>0.927033</td>\n","      <td>0.927033</td>\n","      <td>0.692264</td>\n","      <td>0.642982</td>\n","      <td>0.750422</td>\n","      <td>0.685873</td>\n","      <td>0.634064</td>\n","      <td>0.746902</td>\n","    </tr>\n","    <tr>\n","      <td>15428</td>\n","      <td>0.000000</td>\n","      <td>0.170903</td>\n","      <td>0.675949</td>\n","      <td>0.625671</td>\n","      <td>0.739871</td>\n","      <td>0.928828</td>\n","      <td>0.928828</td>\n","      <td>0.928828</td>\n","      <td>0.694755</td>\n","      <td>0.635816</td>\n","      <td>0.766276</td>\n","      <td>0.687537</td>\n","      <td>0.630722</td>\n","      <td>0.755602</td>\n","    </tr>\n","    <tr>\n","      <td>17632</td>\n","      <td>0.000000</td>\n","      <td>0.172706</td>\n","      <td>0.676818</td>\n","      <td>0.627343</td>\n","      <td>0.739421</td>\n","      <td>0.928990</td>\n","      <td>0.928990</td>\n","      <td>0.928990</td>\n","      <td>0.695822</td>\n","      <td>0.639888</td>\n","      <td>0.762805</td>\n","      <td>0.689871</td>\n","      <td>0.635033</td>\n","      <td>0.755075</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-2204\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-4408\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-6612\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-8816\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-11020\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-13224\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-15428\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-17632\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6768178245796522, 'eval_macro_precision': 0.6273429990119637, 'eval_macro_recall': 0.7394209150391509, 'eval_micro_f1': 0.9289895853548095, 'eval_micro_precision': 0.9289895853548095, 'eval_micro_recall': 0.9289895853548095, 'eval_macro_f1_no_o': 0.6958220053670393, 'eval_macro_precision_no_o': 0.639888369127256, 'eval_macro_recall_no_o': 0.7628046475241331, 'eval_micro_f1_no_o': 0.6898711309165362, 'eval_micro_precision_no_o': 0.6350332594235033, 'eval_micro_recall_no_o': 0.7550751384128658, 'eval_loss': 0.1727057824944293, 'eval_runtime': 42.7393, 'eval_samples_per_second': 11.558, 'eval_steps_per_second': 2.901, 'epoch': 8.0}\n","Accuracy for fold  2 :  0.6898711309165362  --  0.9289895853548095\n","--------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 8816\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 4\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 17632\n"]},{"output_type":"stream","name":"stdout","text":["Testing process has finished.\n","Train run #3\n","--------------------------------\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='17632' max='17632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [17632/17632 1:12:22, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Macro F1</th>\n","      <th>Macro Precision</th>\n","      <th>Macro Recall</th>\n","      <th>Micro F1</th>\n","      <th>Micro Precision</th>\n","      <th>Micro Recall</th>\n","      <th>Macro F1 No O</th>\n","      <th>Macro Precision No O</th>\n","      <th>Macro Recall No O</th>\n","      <th>Micro F1 No O</th>\n","      <th>Micro Precision No O</th>\n","      <th>Micro Recall No O</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>2204</td>\n","      <td>0.000100</td>\n","      <td>0.172189</td>\n","      <td>0.650070</td>\n","      <td>0.615769</td>\n","      <td>0.710723</td>\n","      <td>0.922278</td>\n","      <td>0.922278</td>\n","      <td>0.922278</td>\n","      <td>0.666230</td>\n","      <td>0.657918</td>\n","      <td>0.684872</td>\n","      <td>0.663887</td>\n","      <td>0.620587</td>\n","      <td>0.713683</td>\n","    </tr>\n","    <tr>\n","      <td>4408</td>\n","      <td>0.000100</td>\n","      <td>0.131400</td>\n","      <td>0.653734</td>\n","      <td>0.580293</td>\n","      <td>0.772156</td>\n","      <td>0.910327</td>\n","      <td>0.910327</td>\n","      <td>0.910327</td>\n","      <td>0.671835</td>\n","      <td>0.591412</td>\n","      <td>0.782492</td>\n","      <td>0.664122</td>\n","      <td>0.578299</td>\n","      <td>0.779858</td>\n","    </tr>\n","    <tr>\n","      <td>6612</td>\n","      <td>0.000100</td>\n","      <td>0.122860</td>\n","      <td>0.664354</td>\n","      <td>0.611580</td>\n","      <td>0.735644</td>\n","      <td>0.921745</td>\n","      <td>0.921745</td>\n","      <td>0.921745</td>\n","      <td>0.681167</td>\n","      <td>0.630130</td>\n","      <td>0.750801</td>\n","      <td>0.678220</td>\n","      <td>0.635275</td>\n","      <td>0.727393</td>\n","    </tr>\n","    <tr>\n","      <td>8816</td>\n","      <td>0.000100</td>\n","      <td>0.119737</td>\n","      <td>0.634852</td>\n","      <td>0.551171</td>\n","      <td>0.781672</td>\n","      <td>0.906689</td>\n","      <td>0.906689</td>\n","      <td>0.906689</td>\n","      <td>0.644965</td>\n","      <td>0.554492</td>\n","      <td>0.780912</td>\n","      <td>0.642323</td>\n","      <td>0.557148</td>\n","      <td>0.758239</td>\n","    </tr>\n","    <tr>\n","      <td>11020</td>\n","      <td>0.000000</td>\n","      <td>0.139423</td>\n","      <td>0.675162</td>\n","      <td>0.634404</td>\n","      <td>0.729996</td>\n","      <td>0.925998</td>\n","      <td>0.925998</td>\n","      <td>0.925998</td>\n","      <td>0.690435</td>\n","      <td>0.652579</td>\n","      <td>0.743762</td>\n","      <td>0.679919</td>\n","      <td>0.622861</td>\n","      <td>0.748484</td>\n","    </tr>\n","    <tr>\n","      <td>13224</td>\n","      <td>0.000000</td>\n","      <td>0.145027</td>\n","      <td>0.677469</td>\n","      <td>0.631677</td>\n","      <td>0.737263</td>\n","      <td>0.928084</td>\n","      <td>0.928084</td>\n","      <td>0.928084</td>\n","      <td>0.693349</td>\n","      <td>0.634243</td>\n","      <td>0.770373</td>\n","      <td>0.687375</td>\n","      <td>0.620697</td>\n","      <td>0.770103</td>\n","    </tr>\n","    <tr>\n","      <td>15428</td>\n","      <td>0.000000</td>\n","      <td>0.148289</td>\n","      <td>0.679412</td>\n","      <td>0.634744</td>\n","      <td>0.735759</td>\n","      <td>0.929200</td>\n","      <td>0.929200</td>\n","      <td>0.929200</td>\n","      <td>0.700800</td>\n","      <td>0.655038</td>\n","      <td>0.756863</td>\n","      <td>0.697921</td>\n","      <td>0.654361</td>\n","      <td>0.747693</td>\n","    </tr>\n","    <tr>\n","      <td>17632</td>\n","      <td>0.000000</td>\n","      <td>0.150659</td>\n","      <td>0.678142</td>\n","      <td>0.631840</td>\n","      <td>0.737151</td>\n","      <td>0.929022</td>\n","      <td>0.929022</td>\n","      <td>0.929022</td>\n","      <td>0.698540</td>\n","      <td>0.649705</td>\n","      <td>0.758897</td>\n","      <td>0.696014</td>\n","      <td>0.649031</td>\n","      <td>0.750330</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to trained_scibert_ner_model/checkpoint-2204\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-4408\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-6612\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-8816\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-11020\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-13224\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-15428\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","Saving model checkpoint to trained_scibert_ner_model/checkpoint-17632\n","Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"stream","name":"stdout","text":["Training process has finished.\n","Starting testing\n","{'eval_macro_f1': 0.6781416903871643, 'eval_macro_precision': 0.6318404591442596, 'eval_macro_recall': 0.7371512651503895, 'eval_micro_f1': 0.9290219289734135, 'eval_micro_precision': 0.9290219289734135, 'eval_micro_recall': 0.9290219289734135, 'eval_macro_f1_no_o': 0.6985402448838623, 'eval_macro_precision_no_o': 0.64970505711993, 'eval_macro_recall_no_o': 0.758897329001687, 'eval_micro_f1_no_o': 0.6960136952800196, 'eval_micro_precision_no_o': 0.6490307867730901, 'eval_micro_recall_no_o': 0.7503295544423939, 'eval_loss': 0.15065874749874683, 'eval_runtime': 42.8803, 'eval_samples_per_second': 11.52, 'eval_steps_per_second': 2.892, 'epoch': 8.0}\n","Accuracy for fold  3 :  0.6960136952800196  --  0.9290219289734135\n","--------------------------------\n","Testing process has finished.\n"]}],"source":["loop_val = 4\n","loop_results = np.zeros(loop_val)\n","loop_resultss = np.zeros(loop_val)\n","for r in range(loop_val):\n","\n","  ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","\n","  ner_model.sci_embeddings.requires_grad = False\n","\n","  trainer = MultilabelTrainer(\n","      model=ner_model,\n","      args=training_args,\n","      train_dataset=train,\n","      eval_dataset=test,\n","      data_collator=collator  # defines how to merge data into batches, using the collator function above\n","  )\n","\n","  # Print\n","  print(f'Train run #{r}')\n","  print('--------------------------------')\n","\n","  trainer.train()\n","\n","  # Process is complete.\n","  print('Training process has finished.')\n","\n","  # Print about testing\n","  print('Starting testing')\n","\n","  with torch.no_grad():\n","    result = trainer.evaluate(test)\n","    print(result)\n","\n","    # Print accuracy\n","    print('Accuracy for fold ', r, ': ', result['eval_micro_f1_no_o'], ' -- ', result['eval_micro_f1'])\n","    print('--------------------------------')\n","    loop_results[r] = result['eval_micro_f1_no_o']\n","    loop_resultss[r] = result['eval_micro_f1']\n","    del result\n","\n","  if r > 0:\n","    if loop_results[r] < loop_results[r-1]:\n","      save_path = f'./model-fold-{r}.pth'\n","      torch.save(ner_model.state_dict(), save_path)\n","\n","  print('Testing process has finished.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wpkvea8G6EuP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691011783500,"user_tz":360,"elapsed":0,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"5cca552a-4161-4140-b04e-123ee0121845"},"outputs":[{"data":{"text/plain":["array([0.69574674, 0.69016833, 0.68987113, 0.6960137 ])"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["loop_results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUMuY7uY6Epd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691011783501,"user_tz":360,"elapsed":0,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"ce1090bf-6ada-472d-d9ea-c9e62977d125"},"outputs":[{"data":{"text/plain":["array([0.92742092, 0.92902193, 0.92898959, 0.92902193])"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["loop_resultss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrSHvYq06Ej1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691011783498,"user_tz":360,"elapsed":8,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"35dd5526-5638-410c-82d9-7348b9cb6a93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Average micro_f1_no_o: 0.6929499743727167 %\n","Average micro_f1: 0.9286135907885373 %\n"]}],"source":["sum = 0.0\n","for value in loop_results:\n","  sum += value\n","print(f'Average micro_f1_no_o: {sum/len(loop_results)} %')\n","\n","sum = 0.0\n","for value in loop_resultss:\n","  sum += value\n","print(f'Average micro_f1: {sum/len(loop_results)} %')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASHUrO0o6EcH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691011785737,"user_tz":360,"elapsed":2242,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"07499402-3c7b-4748-8db5-5c34b2b1c9ef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=768, out_features=14, bias=True)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=13, bias=True)\n",")"]},"metadata":{},"execution_count":49}],"source":["ner_model = NerModel(BertEmbModel).to('cuda')  # make sure we move the model to the GPU for training\n","ner_model.load_state_dict(torch.load(save_path))\n","ner_model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k9ruMQIcAQ_K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691011785738,"user_tz":360,"elapsed":6,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"214a532e-0aad-4709-8ed5-507a28a960c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["100\n"]}],"source":["A=100\n","print(A)"]},{"cell_type":"markdown","metadata":{"id":"dcdDIwq0kXy2"},"source":["# Get Values of Thruth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCnsc2rplFzW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691011785739,"user_tz":360,"elapsed":4,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"9daff62b-6f41-4934-cecc-00c4da799d78"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=768, out_features=14, bias=True)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=13, bias=True)\n",")"]},"metadata":{},"execution_count":51}],"source":["# Pytorch thing (if we aren't training, do this)\n","ner_model.eval()\n","ner_model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FVfjoHmcI0pL"},"outputs":[],"source":["output_preds = []\n","output_real = []\n","for x in range(len(test)):\n","  inputs1 = test[x]['input_ids'][0].clone().detach().to(torch.long).unsqueeze(0).to('cuda')\n","  inputs2 = test[x]['attention_mask'][0].clone().detach().to(torch.long).unsqueeze(0).to('cuda')\n","  inputs = {'input_ids': inputs1,  'attention_mask': inputs2}\n","  #print(inputs)\n","\n","  temp_test = test[x]\n","  temp_out = temp_test.pop(\"labels\")\n","  output_real.append(np.array(temp_out[temp_out != -100]))\n","\n","  gen_preds = ner_model(**inputs)\n","  label_preds = np.argmax(gen_preds.cpu().detach().numpy(), axis=-1)[0]\n","  output_preds.append(label_preds[temp_out != -100])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXBvXjpP-VGh"},"outputs":[],"source":["for x in range(len(output_real)):\n","  output_real[x] = [ID2Entity(y) for y in output_real[x]]\n","  output_preds[x] = [ID2Entity(z) for z in output_preds[x]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pd1Xl1giQ7z7"},"outputs":[],"source":["#output_real[28]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5rslGT68vvC8"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error, multilabel_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay, precision_recall_fscore_support\n","import matplotlib.pyplot as plt\n","\n","plt.rcParams['figure.figsize'] = [15, 12]\n","plt.rcParams[\"figure.autolayout\"] = True\n","plt.rcParams.update({'font.size': 13})\n","\n","labels = [\"O\", \"B-Task\", \"I-Task\", \"B-Method\", \"I-Method\", \"B-Metric\", \"I-Metric\", \"B-Material\", \"I-Material\", \"B-OtherScientificTerm\", \"I-OtherScientificTerm\", \"B-Generic\", \"I-Generic\"]\n","cm = confusion_matrix(output_real[0], output_preds[0], labels=labels)\n","for x in range(len(output_real)-1):\n","  cm += confusion_matrix(output_real[x+1], output_preds[x+1], labels=labels)\n","print(cm)\n","disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","disp.plot(cmap=plt.cm.Blues)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m10aBi5x5Hdb"},"outputs":[],"source":["del cm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgGd1XfheERK"},"outputs":[],"source":["len(output_real)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fHlg1QV3eZCa"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"k0w9Lc0d3iOT"},"source":["# Test over Text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgNM3p1q3hrf"},"outputs":[],"source":["def prepare_input(txt):\n","  inputs = BertTokenizer(txt, return_tensors='pt', padding='max_length', truncation=True, max_length=150).to('cuda')\n","  return inputs\n","\n","input_text = [\"English is shown to be trans-context-free on the basis of coordinations of the respectively type that involve strictly syntactic cross-serial agreement.\"]\n","##input_text = [\"The transient analysis of gyro-elastic structured media, composed of periodically placed masses interconnected by elastic rods and attached to gyroscopic spinners, is presented.\"]\n","##input_text = [\"The results indicated that thermal curing promoted the early strength of mortars, while decreased the late strength of mortars.\"]\n","##input_text = [\"A wide variety of processes are attested in the literature, and we find different forms of clippings in our data, including mixtures of different clippings, homophone respellings, phonetic respellings in-cluding informal oral forms, initialisms (but no acronyms), and mixtures of clipping together with homo-phone and phonetic respellings.\"]\n","\n","#input_text = [\"The goal is to accurately predict the running time of applications for task scheduling and job migration.\"]\n","#input_text = [\"This paper reports on the development of a cross-domain framework for describing complex design practices.\"]\n","#input_text = [\"Studies of inequality in China typically ignore cost of liv-ing differences between areas.\"]\n","#input_text = [\"The present study was designed to explore the long-term differences be-tween three mouse models for depression.\"]\n","#\n","input_text = [\"Finally, regarding professional competencies, teachers appeared to be largely unprepared to conduct language assessments consistent with the LAR demands.\"]\n","\n","##input_text = [\"propose a fast and reliable restoration method of virtual resources on OpenStack when physical servers or virtual machines are down.\"]\n","##input_text = [\"The results from our simulations reveal that the network assisted adaptation clearly outperforms the purely client-based DASH heuristics in some of the metrics, not all of them, particularly, in situations when the achievable throughput is moderately high or the link quality of the mobile clients does not differ from each other substantially.\"]\n","##input_text = [\"For hard rock drilling in coal mine, the drilling efficiency and service life of polycrystalline diamond compact bit are very low.\"]\n","##input_text = [\"Capturing changes in foreign reserves and exchange rates through the exchange market pressure, this article investigates whether economic policy uncertainty plays any role in exchange market pressure movements while controlling for the effects of domestic and external factors.\"]\n","##input_text = [\"This paper presents design of an self contained actuators unit in wide area damping control of power system in stabilizing system response for both nominal system condition and during actuator faults.\"]\n","\n","##input_text = [\"Ultrasound-based brain stimulation techniques may become a powerful new technique to modulate the human brain in a focal and targeted manner.\"]\n","#input_text = [\"Recent work pre-training Transformers with self-supervised objectives on large text corpora has shown great success when fine-tuned on downstream NLP tasks including text summarization.\"]\n","\n","# Tokenize + pad\n","inputs = prepare_input(input_text)\n","\n","#inputs\n","#print(inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1645211610139,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"jaG1vUq58BFI","outputId":"ce95fec4-a4cd-4608-fc55-75b5b485c9e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["finally -> None\n",", -> None\n","regarding -> None\n","professional -> None\n","competencies -> None\n",", -> None\n","teachers -> None\n","appeared -> None\n","to -> None\n","be -> None\n","largely -> None\n","un -> None\n","##prep -> None\n","##ared -> None\n","to -> None\n","conduct -> None\n","language -> None\n","assessments -> None\n","consistent -> None\n","with -> None\n","the -> None\n","lar -> B\n","demands -> None\n",". -> None\n"]}],"source":["# Pytorch thing (if we aren't training, do this)\n","ner_model.eval()\n","\n","# Get predictions\n","preds = ner_model(**inputs).cpu().detach().numpy()\n","preds = np.argmax(preds, axis=-1)[0]\n","pred_labels = [ID2Entity(x) for x in preds]\n","\n","# Convert token ids to text\n","tokens = BertTokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n","\n","# Display result\n","for token, label in zip(tokens, pred_labels):\n","  if token == '[SEP]':\n","    break\n","  if token == '[CLS]':\n","    continue\n","  print('{} -> {}'.format(token, label))"]},{"cell_type":"markdown","metadata":{"id":"hC35X0v72kXB"},"source":["# Model Save and Load"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1639143321741,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"AnK4H5vP2kJU","outputId":"537a928e-691b-4471-f65b-b7650341f273"},"outputs":[{"name":"stdout","output_type":"stream","text":["Our model: \n","\n"," NerModel(\n","  (sci_embeddings): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (embd_dropout): Dropout(p=0.1, inplace=False)\n","  (ff_dropout): Dropout(p=0.1, inplace=False)\n","  (ff): Linear(in_features=200, out_features=14, bias=True)\n","  (tanh): Tanh()\n","  (lstm): LSTM(768, 100, bidirectional=True)\n","  (lstm_drop): Dropout(p=0.4, inplace=False)\n","  (ff_act): ReLU()\n","  (classifier): Linear(in_features=14, out_features=3, bias=True)\n",") \n","\n","The state dict keys: \n","\n"," odict_keys(['sci_embeddings.embeddings.position_ids', 'sci_embeddings.embeddings.word_embeddings.weight', 'sci_embeddings.embeddings.position_embeddings.weight', 'sci_embeddings.embeddings.token_type_embeddings.weight', 'sci_embeddings.embeddings.LayerNorm.weight', 'sci_embeddings.embeddings.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.attention.self.query.weight', 'sci_embeddings.encoder.layer.0.attention.self.query.bias', 'sci_embeddings.encoder.layer.0.attention.self.key.weight', 'sci_embeddings.encoder.layer.0.attention.self.key.bias', 'sci_embeddings.encoder.layer.0.attention.self.value.weight', 'sci_embeddings.encoder.layer.0.attention.self.value.bias', 'sci_embeddings.encoder.layer.0.attention.output.dense.weight', 'sci_embeddings.encoder.layer.0.attention.output.dense.bias', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.intermediate.dense.weight', 'sci_embeddings.encoder.layer.0.intermediate.dense.bias', 'sci_embeddings.encoder.layer.0.output.dense.weight', 'sci_embeddings.encoder.layer.0.output.dense.bias', 'sci_embeddings.encoder.layer.0.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.attention.self.query.weight', 'sci_embeddings.encoder.layer.1.attention.self.query.bias', 'sci_embeddings.encoder.layer.1.attention.self.key.weight', 'sci_embeddings.encoder.layer.1.attention.self.key.bias', 'sci_embeddings.encoder.layer.1.attention.self.value.weight', 'sci_embeddings.encoder.layer.1.attention.self.value.bias', 'sci_embeddings.encoder.layer.1.attention.output.dense.weight', 'sci_embeddings.encoder.layer.1.attention.output.dense.bias', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.intermediate.dense.weight', 'sci_embeddings.encoder.layer.1.intermediate.dense.bias', 'sci_embeddings.encoder.layer.1.output.dense.weight', 'sci_embeddings.encoder.layer.1.output.dense.bias', 'sci_embeddings.encoder.layer.1.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.attention.self.query.weight', 'sci_embeddings.encoder.layer.2.attention.self.query.bias', 'sci_embeddings.encoder.layer.2.attention.self.key.weight', 'sci_embeddings.encoder.layer.2.attention.self.key.bias', 'sci_embeddings.encoder.layer.2.attention.self.value.weight', 'sci_embeddings.encoder.layer.2.attention.self.value.bias', 'sci_embeddings.encoder.layer.2.attention.output.dense.weight', 'sci_embeddings.encoder.layer.2.attention.output.dense.bias', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.intermediate.dense.weight', 'sci_embeddings.encoder.layer.2.intermediate.dense.bias', 'sci_embeddings.encoder.layer.2.output.dense.weight', 'sci_embeddings.encoder.layer.2.output.dense.bias', 'sci_embeddings.encoder.layer.2.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.attention.self.query.weight', 'sci_embeddings.encoder.layer.3.attention.self.query.bias', 'sci_embeddings.encoder.layer.3.attention.self.key.weight', 'sci_embeddings.encoder.layer.3.attention.self.key.bias', 'sci_embeddings.encoder.layer.3.attention.self.value.weight', 'sci_embeddings.encoder.layer.3.attention.self.value.bias', 'sci_embeddings.encoder.layer.3.attention.output.dense.weight', 'sci_embeddings.encoder.layer.3.attention.output.dense.bias', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.intermediate.dense.weight', 'sci_embeddings.encoder.layer.3.intermediate.dense.bias', 'sci_embeddings.encoder.layer.3.output.dense.weight', 'sci_embeddings.encoder.layer.3.output.dense.bias', 'sci_embeddings.encoder.layer.3.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.attention.self.query.weight', 'sci_embeddings.encoder.layer.4.attention.self.query.bias', 'sci_embeddings.encoder.layer.4.attention.self.key.weight', 'sci_embeddings.encoder.layer.4.attention.self.key.bias', 'sci_embeddings.encoder.layer.4.attention.self.value.weight', 'sci_embeddings.encoder.layer.4.attention.self.value.bias', 'sci_embeddings.encoder.layer.4.attention.output.dense.weight', 'sci_embeddings.encoder.layer.4.attention.output.dense.bias', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.intermediate.dense.weight', 'sci_embeddings.encoder.layer.4.intermediate.dense.bias', 'sci_embeddings.encoder.layer.4.output.dense.weight', 'sci_embeddings.encoder.layer.4.output.dense.bias', 'sci_embeddings.encoder.layer.4.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.attention.self.query.weight', 'sci_embeddings.encoder.layer.5.attention.self.query.bias', 'sci_embeddings.encoder.layer.5.attention.self.key.weight', 'sci_embeddings.encoder.layer.5.attention.self.key.bias', 'sci_embeddings.encoder.layer.5.attention.self.value.weight', 'sci_embeddings.encoder.layer.5.attention.self.value.bias', 'sci_embeddings.encoder.layer.5.attention.output.dense.weight', 'sci_embeddings.encoder.layer.5.attention.output.dense.bias', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.intermediate.dense.weight', 'sci_embeddings.encoder.layer.5.intermediate.dense.bias', 'sci_embeddings.encoder.layer.5.output.dense.weight', 'sci_embeddings.encoder.layer.5.output.dense.bias', 'sci_embeddings.encoder.layer.5.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.attention.self.query.weight', 'sci_embeddings.encoder.layer.6.attention.self.query.bias', 'sci_embeddings.encoder.layer.6.attention.self.key.weight', 'sci_embeddings.encoder.layer.6.attention.self.key.bias', 'sci_embeddings.encoder.layer.6.attention.self.value.weight', 'sci_embeddings.encoder.layer.6.attention.self.value.bias', 'sci_embeddings.encoder.layer.6.attention.output.dense.weight', 'sci_embeddings.encoder.layer.6.attention.output.dense.bias', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.intermediate.dense.weight', 'sci_embeddings.encoder.layer.6.intermediate.dense.bias', 'sci_embeddings.encoder.layer.6.output.dense.weight', 'sci_embeddings.encoder.layer.6.output.dense.bias', 'sci_embeddings.encoder.layer.6.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.attention.self.query.weight', 'sci_embeddings.encoder.layer.7.attention.self.query.bias', 'sci_embeddings.encoder.layer.7.attention.self.key.weight', 'sci_embeddings.encoder.layer.7.attention.self.key.bias', 'sci_embeddings.encoder.layer.7.attention.self.value.weight', 'sci_embeddings.encoder.layer.7.attention.self.value.bias', 'sci_embeddings.encoder.layer.7.attention.output.dense.weight', 'sci_embeddings.encoder.layer.7.attention.output.dense.bias', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.intermediate.dense.weight', 'sci_embeddings.encoder.layer.7.intermediate.dense.bias', 'sci_embeddings.encoder.layer.7.output.dense.weight', 'sci_embeddings.encoder.layer.7.output.dense.bias', 'sci_embeddings.encoder.layer.7.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.attention.self.query.weight', 'sci_embeddings.encoder.layer.8.attention.self.query.bias', 'sci_embeddings.encoder.layer.8.attention.self.key.weight', 'sci_embeddings.encoder.layer.8.attention.self.key.bias', 'sci_embeddings.encoder.layer.8.attention.self.value.weight', 'sci_embeddings.encoder.layer.8.attention.self.value.bias', 'sci_embeddings.encoder.layer.8.attention.output.dense.weight', 'sci_embeddings.encoder.layer.8.attention.output.dense.bias', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.intermediate.dense.weight', 'sci_embeddings.encoder.layer.8.intermediate.dense.bias', 'sci_embeddings.encoder.layer.8.output.dense.weight', 'sci_embeddings.encoder.layer.8.output.dense.bias', 'sci_embeddings.encoder.layer.8.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.attention.self.query.weight', 'sci_embeddings.encoder.layer.9.attention.self.query.bias', 'sci_embeddings.encoder.layer.9.attention.self.key.weight', 'sci_embeddings.encoder.layer.9.attention.self.key.bias', 'sci_embeddings.encoder.layer.9.attention.self.value.weight', 'sci_embeddings.encoder.layer.9.attention.self.value.bias', 'sci_embeddings.encoder.layer.9.attention.output.dense.weight', 'sci_embeddings.encoder.layer.9.attention.output.dense.bias', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.intermediate.dense.weight', 'sci_embeddings.encoder.layer.9.intermediate.dense.bias', 'sci_embeddings.encoder.layer.9.output.dense.weight', 'sci_embeddings.encoder.layer.9.output.dense.bias', 'sci_embeddings.encoder.layer.9.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.attention.self.query.weight', 'sci_embeddings.encoder.layer.10.attention.self.query.bias', 'sci_embeddings.encoder.layer.10.attention.self.key.weight', 'sci_embeddings.encoder.layer.10.attention.self.key.bias', 'sci_embeddings.encoder.layer.10.attention.self.value.weight', 'sci_embeddings.encoder.layer.10.attention.self.value.bias', 'sci_embeddings.encoder.layer.10.attention.output.dense.weight', 'sci_embeddings.encoder.layer.10.attention.output.dense.bias', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.intermediate.dense.weight', 'sci_embeddings.encoder.layer.10.intermediate.dense.bias', 'sci_embeddings.encoder.layer.10.output.dense.weight', 'sci_embeddings.encoder.layer.10.output.dense.bias', 'sci_embeddings.encoder.layer.10.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.attention.self.query.weight', 'sci_embeddings.encoder.layer.11.attention.self.query.bias', 'sci_embeddings.encoder.layer.11.attention.self.key.weight', 'sci_embeddings.encoder.layer.11.attention.self.key.bias', 'sci_embeddings.encoder.layer.11.attention.self.value.weight', 'sci_embeddings.encoder.layer.11.attention.self.value.bias', 'sci_embeddings.encoder.layer.11.attention.output.dense.weight', 'sci_embeddings.encoder.layer.11.attention.output.dense.bias', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.intermediate.dense.weight', 'sci_embeddings.encoder.layer.11.intermediate.dense.bias', 'sci_embeddings.encoder.layer.11.output.dense.weight', 'sci_embeddings.encoder.layer.11.output.dense.bias', 'sci_embeddings.encoder.layer.11.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.output.LayerNorm.bias', 'sci_embeddings.pooler.dense.weight', 'sci_embeddings.pooler.dense.bias', 'ff.weight', 'ff.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'classifier.weight', 'classifier.bias'])\n"]}],"source":["print(\"Our model: \\n\\n\", ner_model, '\\n')\n","print(\"The state dict keys: \\n\\n\", ner_model.state_dict().keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KftdO6GD2rWF"},"outputs":[],"source":["torch.save(ner_model.state_dict(), 'trained_model_dic.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1639143322986,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"n2xrcRkQbwvH","outputId":"724e6884-3d3f-440d-bbe2-2030ac185d8b"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_d7f824df-1211-4d38-b2b6-dec4d84cde45\", \"trained_model_dic.pth\", 442559399)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["# download checkpoint file\n","files.download('trained_model_dic.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1637655465909,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"l1hvL5Nb3kmo","outputId":"a2910628-2592-4edd-b135-c329d0352c5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["checkpoint.pth\t  model-fold-1.pth  model-fold-4.pth  trained_model_dic.pth\n","dev.json\t  model-fold-2.pth  sample_data       trained_scibert_ner_model\n","model-fold-0.pth  model-fold-3.pth  test.json\t      train.json\n"]}],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"hQL7fqSY2x9e"},"source":["Loading the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1638565657653,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"2ufmrdfeT6Qz","outputId":"fd7fd743-41b0-4b32-eefd-db4f427d5da0"},"outputs":[{"name":"stdout","output_type":"stream","text":["sample_data  test_500_v2.conll\ttrain_1500_v2.conll  trained_model_dic.pth\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10896,"status":"ok","timestamp":1638831550021,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"a4Eus2gmJ-bS","outputId":"1e8838d1-d51c-47db-8ee2-c0bbb2bb3a0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["odict_keys(['sci_embeddings.embeddings.position_ids', 'sci_embeddings.embeddings.word_embeddings.weight', 'sci_embeddings.embeddings.position_embeddings.weight', 'sci_embeddings.embeddings.token_type_embeddings.weight', 'sci_embeddings.embeddings.LayerNorm.weight', 'sci_embeddings.embeddings.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.attention.self.query.weight', 'sci_embeddings.encoder.layer.0.attention.self.query.bias', 'sci_embeddings.encoder.layer.0.attention.self.key.weight', 'sci_embeddings.encoder.layer.0.attention.self.key.bias', 'sci_embeddings.encoder.layer.0.attention.self.value.weight', 'sci_embeddings.encoder.layer.0.attention.self.value.bias', 'sci_embeddings.encoder.layer.0.attention.output.dense.weight', 'sci_embeddings.encoder.layer.0.attention.output.dense.bias', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.0.intermediate.dense.weight', 'sci_embeddings.encoder.layer.0.intermediate.dense.bias', 'sci_embeddings.encoder.layer.0.output.dense.weight', 'sci_embeddings.encoder.layer.0.output.dense.bias', 'sci_embeddings.encoder.layer.0.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.0.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.attention.self.query.weight', 'sci_embeddings.encoder.layer.1.attention.self.query.bias', 'sci_embeddings.encoder.layer.1.attention.self.key.weight', 'sci_embeddings.encoder.layer.1.attention.self.key.bias', 'sci_embeddings.encoder.layer.1.attention.self.value.weight', 'sci_embeddings.encoder.layer.1.attention.self.value.bias', 'sci_embeddings.encoder.layer.1.attention.output.dense.weight', 'sci_embeddings.encoder.layer.1.attention.output.dense.bias', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.1.intermediate.dense.weight', 'sci_embeddings.encoder.layer.1.intermediate.dense.bias', 'sci_embeddings.encoder.layer.1.output.dense.weight', 'sci_embeddings.encoder.layer.1.output.dense.bias', 'sci_embeddings.encoder.layer.1.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.1.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.attention.self.query.weight', 'sci_embeddings.encoder.layer.2.attention.self.query.bias', 'sci_embeddings.encoder.layer.2.attention.self.key.weight', 'sci_embeddings.encoder.layer.2.attention.self.key.bias', 'sci_embeddings.encoder.layer.2.attention.self.value.weight', 'sci_embeddings.encoder.layer.2.attention.self.value.bias', 'sci_embeddings.encoder.layer.2.attention.output.dense.weight', 'sci_embeddings.encoder.layer.2.attention.output.dense.bias', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.2.intermediate.dense.weight', 'sci_embeddings.encoder.layer.2.intermediate.dense.bias', 'sci_embeddings.encoder.layer.2.output.dense.weight', 'sci_embeddings.encoder.layer.2.output.dense.bias', 'sci_embeddings.encoder.layer.2.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.2.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.attention.self.query.weight', 'sci_embeddings.encoder.layer.3.attention.self.query.bias', 'sci_embeddings.encoder.layer.3.attention.self.key.weight', 'sci_embeddings.encoder.layer.3.attention.self.key.bias', 'sci_embeddings.encoder.layer.3.attention.self.value.weight', 'sci_embeddings.encoder.layer.3.attention.self.value.bias', 'sci_embeddings.encoder.layer.3.attention.output.dense.weight', 'sci_embeddings.encoder.layer.3.attention.output.dense.bias', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.3.intermediate.dense.weight', 'sci_embeddings.encoder.layer.3.intermediate.dense.bias', 'sci_embeddings.encoder.layer.3.output.dense.weight', 'sci_embeddings.encoder.layer.3.output.dense.bias', 'sci_embeddings.encoder.layer.3.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.3.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.attention.self.query.weight', 'sci_embeddings.encoder.layer.4.attention.self.query.bias', 'sci_embeddings.encoder.layer.4.attention.self.key.weight', 'sci_embeddings.encoder.layer.4.attention.self.key.bias', 'sci_embeddings.encoder.layer.4.attention.self.value.weight', 'sci_embeddings.encoder.layer.4.attention.self.value.bias', 'sci_embeddings.encoder.layer.4.attention.output.dense.weight', 'sci_embeddings.encoder.layer.4.attention.output.dense.bias', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.4.intermediate.dense.weight', 'sci_embeddings.encoder.layer.4.intermediate.dense.bias', 'sci_embeddings.encoder.layer.4.output.dense.weight', 'sci_embeddings.encoder.layer.4.output.dense.bias', 'sci_embeddings.encoder.layer.4.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.4.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.attention.self.query.weight', 'sci_embeddings.encoder.layer.5.attention.self.query.bias', 'sci_embeddings.encoder.layer.5.attention.self.key.weight', 'sci_embeddings.encoder.layer.5.attention.self.key.bias', 'sci_embeddings.encoder.layer.5.attention.self.value.weight', 'sci_embeddings.encoder.layer.5.attention.self.value.bias', 'sci_embeddings.encoder.layer.5.attention.output.dense.weight', 'sci_embeddings.encoder.layer.5.attention.output.dense.bias', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.5.intermediate.dense.weight', 'sci_embeddings.encoder.layer.5.intermediate.dense.bias', 'sci_embeddings.encoder.layer.5.output.dense.weight', 'sci_embeddings.encoder.layer.5.output.dense.bias', 'sci_embeddings.encoder.layer.5.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.5.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.attention.self.query.weight', 'sci_embeddings.encoder.layer.6.attention.self.query.bias', 'sci_embeddings.encoder.layer.6.attention.self.key.weight', 'sci_embeddings.encoder.layer.6.attention.self.key.bias', 'sci_embeddings.encoder.layer.6.attention.self.value.weight', 'sci_embeddings.encoder.layer.6.attention.self.value.bias', 'sci_embeddings.encoder.layer.6.attention.output.dense.weight', 'sci_embeddings.encoder.layer.6.attention.output.dense.bias', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.6.intermediate.dense.weight', 'sci_embeddings.encoder.layer.6.intermediate.dense.bias', 'sci_embeddings.encoder.layer.6.output.dense.weight', 'sci_embeddings.encoder.layer.6.output.dense.bias', 'sci_embeddings.encoder.layer.6.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.6.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.attention.self.query.weight', 'sci_embeddings.encoder.layer.7.attention.self.query.bias', 'sci_embeddings.encoder.layer.7.attention.self.key.weight', 'sci_embeddings.encoder.layer.7.attention.self.key.bias', 'sci_embeddings.encoder.layer.7.attention.self.value.weight', 'sci_embeddings.encoder.layer.7.attention.self.value.bias', 'sci_embeddings.encoder.layer.7.attention.output.dense.weight', 'sci_embeddings.encoder.layer.7.attention.output.dense.bias', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.7.intermediate.dense.weight', 'sci_embeddings.encoder.layer.7.intermediate.dense.bias', 'sci_embeddings.encoder.layer.7.output.dense.weight', 'sci_embeddings.encoder.layer.7.output.dense.bias', 'sci_embeddings.encoder.layer.7.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.7.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.attention.self.query.weight', 'sci_embeddings.encoder.layer.8.attention.self.query.bias', 'sci_embeddings.encoder.layer.8.attention.self.key.weight', 'sci_embeddings.encoder.layer.8.attention.self.key.bias', 'sci_embeddings.encoder.layer.8.attention.self.value.weight', 'sci_embeddings.encoder.layer.8.attention.self.value.bias', 'sci_embeddings.encoder.layer.8.attention.output.dense.weight', 'sci_embeddings.encoder.layer.8.attention.output.dense.bias', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.8.intermediate.dense.weight', 'sci_embeddings.encoder.layer.8.intermediate.dense.bias', 'sci_embeddings.encoder.layer.8.output.dense.weight', 'sci_embeddings.encoder.layer.8.output.dense.bias', 'sci_embeddings.encoder.layer.8.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.8.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.attention.self.query.weight', 'sci_embeddings.encoder.layer.9.attention.self.query.bias', 'sci_embeddings.encoder.layer.9.attention.self.key.weight', 'sci_embeddings.encoder.layer.9.attention.self.key.bias', 'sci_embeddings.encoder.layer.9.attention.self.value.weight', 'sci_embeddings.encoder.layer.9.attention.self.value.bias', 'sci_embeddings.encoder.layer.9.attention.output.dense.weight', 'sci_embeddings.encoder.layer.9.attention.output.dense.bias', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.9.intermediate.dense.weight', 'sci_embeddings.encoder.layer.9.intermediate.dense.bias', 'sci_embeddings.encoder.layer.9.output.dense.weight', 'sci_embeddings.encoder.layer.9.output.dense.bias', 'sci_embeddings.encoder.layer.9.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.9.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.attention.self.query.weight', 'sci_embeddings.encoder.layer.10.attention.self.query.bias', 'sci_embeddings.encoder.layer.10.attention.self.key.weight', 'sci_embeddings.encoder.layer.10.attention.self.key.bias', 'sci_embeddings.encoder.layer.10.attention.self.value.weight', 'sci_embeddings.encoder.layer.10.attention.self.value.bias', 'sci_embeddings.encoder.layer.10.attention.output.dense.weight', 'sci_embeddings.encoder.layer.10.attention.output.dense.bias', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.10.intermediate.dense.weight', 'sci_embeddings.encoder.layer.10.intermediate.dense.bias', 'sci_embeddings.encoder.layer.10.output.dense.weight', 'sci_embeddings.encoder.layer.10.output.dense.bias', 'sci_embeddings.encoder.layer.10.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.10.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.attention.self.query.weight', 'sci_embeddings.encoder.layer.11.attention.self.query.bias', 'sci_embeddings.encoder.layer.11.attention.self.key.weight', 'sci_embeddings.encoder.layer.11.attention.self.key.bias', 'sci_embeddings.encoder.layer.11.attention.self.value.weight', 'sci_embeddings.encoder.layer.11.attention.self.value.bias', 'sci_embeddings.encoder.layer.11.attention.output.dense.weight', 'sci_embeddings.encoder.layer.11.attention.output.dense.bias', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.attention.output.LayerNorm.bias', 'sci_embeddings.encoder.layer.11.intermediate.dense.weight', 'sci_embeddings.encoder.layer.11.intermediate.dense.bias', 'sci_embeddings.encoder.layer.11.output.dense.weight', 'sci_embeddings.encoder.layer.11.output.dense.bias', 'sci_embeddings.encoder.layer.11.output.LayerNorm.weight', 'sci_embeddings.encoder.layer.11.output.LayerNorm.bias', 'sci_embeddings.pooler.dense.weight', 'sci_embeddings.pooler.dense.bias', 'ff.weight', 'ff.bias', 'lstm.weight_ih_l0', 'lstm.weight_hh_l0', 'lstm.bias_ih_l0', 'lstm.bias_hh_l0', 'lstm.weight_ih_l0_reverse', 'lstm.weight_hh_l0_reverse', 'lstm.bias_ih_l0_reverse', 'lstm.bias_hh_l0_reverse', 'classifier.weight', 'classifier.bias'])\n"]}],"source":["state_dict = torch.load('trained_model_dic.pth')\n","print(state_dict.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209,"status":"ok","timestamp":1638831550219,"user":{"displayName":"Andres Erazo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gig70EzHF1rGC2-hxB0urBdpvl-4KrirMXydyMlpA=s64","userId":"09584327625341777910"},"user_tz":360},"id":"TCFtuyBv3ADq","outputId":"40928121-bd3b-422d-e0c7-53907b33e69b"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["ner_model = NerModel(BertEmbModel).to('cuda')\n","ner_model.load_state_dict(state_dict)"]},{"cell_type":"markdown","metadata":{"id":"ymiejDO5srYE"},"source":["# Obtain datasets' weights values (Do not run - fixed values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GsRs55zcsxhk","colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"status":"error","timestamp":1690872989573,"user_tz":360,"elapsed":5342180,"user":{"displayName":"Andres Erazo","userId":"09584327625341777910"}},"outputId":"8705d329-00cd-4f12-9d65-7ca1900a694e"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-32adaa92cd1e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mone\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mtwo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-e47de2a7d362>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#return {input_ids, labels}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-e47de2a7d362>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#return {input_ids, labels}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["zero = 0\n","one=0\n","two=0\n","three=0\n","four=0\n","five=0\n","six=0\n","local_set = train\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","\n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YzN52yRfsym4"},"outputs":[],"source":["zero = 0\n","one=0\n","two=0\n","three=0\n","four=0\n","five=0\n","six=0\n","local_set = test\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","\n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B64qF5V-trfK"},"outputs":[],"source":["zero = 0\n","one=0\n","two=0\n","three=0\n","four=0\n","five=0\n","six=0\n","local_set = val\n","for i in range(len(local_set)):\n","  for j in range(len(local_set[i]['labels'])):\n","    if local_set[i]['labels'][j] == 0:\n","      zero += 1\n","    elif local_set[i]['labels'][j] == 1:\n","      one += 1\n","    elif local_set[i]['labels'][j] == 2:\n","      two += 1\n","    elif local_set[i]['labels'][j] == 3:\n","      three += 1\n","    elif local_set[i]['labels'][j] == 4:\n","      four += 1\n","    elif local_set[i]['labels'][j] == 5:\n","      five += 1\n","    elif local_set[i]['labels'][j] == 6:\n","      six += 1\n","\n","print('0: ', zero, '1: ', one, '2: ', two, '3: ', three, '4: ', four, '5: ', five, '6: ', six)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEKHdlDyy1T2"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["LyMVIljFrioE","52t8l945rf1Y","-DBrafz0KqEq","XEm8RAgPDipK","igV5vNz9FSFN","SneST94BFvSI","oGYV8ipcJ5fU","7LthVVOhx_Sz","1Nh8Lcpvb_F4","kv6pGzbGpv2D","BBA4owXH8oS1","k0w9Lc0d3iOT","hC35X0v72kXB","ymiejDO5srYE"],"provenance":[{"file_id":"1apRBKJ_i2t4gsKy0TfRAM0Gih4gDkI15","timestamp":1634538734401}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d954d023b55d4221ab2ff9d1c11958fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_675ceaf5d35849b89e7e724b3a0bcac5","IPY_MODEL_de35970352474f74964a16842642fa0b","IPY_MODEL_0aad36d289b54104a3af8d54e2810c67"],"layout":"IPY_MODEL_b40eb62ecfee44d6b66429d995070f6d"}},"675ceaf5d35849b89e7e724b3a0bcac5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa946f38ce44492f89f51f7730085b21","placeholder":"​","style":"IPY_MODEL_51a1d2b75dc54b85a1da482d7faec8a0","value":"Downloading: 100%"}},"de35970352474f74964a16842642fa0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d19905d73a2403d9f935e96d317ee70","max":385,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03c7491b03e140ca91641ebec69b728c","value":385}},"0aad36d289b54104a3af8d54e2810c67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4884de943af4c7f88a40e658b7dab31","placeholder":"​","style":"IPY_MODEL_e034800afe0040b68f0bf36a602e3ff7","value":" 385/385 [00:00&lt;00:00, 8.23kB/s]"}},"b40eb62ecfee44d6b66429d995070f6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa946f38ce44492f89f51f7730085b21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51a1d2b75dc54b85a1da482d7faec8a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d19905d73a2403d9f935e96d317ee70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03c7491b03e140ca91641ebec69b728c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4884de943af4c7f88a40e658b7dab31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e034800afe0040b68f0bf36a602e3ff7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a264b7a8aa146e68d7ec87ebd31b4e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a07428380d842558a015c33c50133b9","IPY_MODEL_0e6c9115c51f4a7ca388d8ed8a40b9e6","IPY_MODEL_51b5e31bb90149fa87e6c7a46c3ba28b"],"layout":"IPY_MODEL_acf35e2b012a4908bfa1b7684d84692a"}},"1a07428380d842558a015c33c50133b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0bda6b9fc294107b0974c8649cb3dfb","placeholder":"​","style":"IPY_MODEL_06fcfa646f2341deb5e9baa825485f90","value":"Downloading: 100%"}},"0e6c9115c51f4a7ca388d8ed8a40b9e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_710c1d0b690044f09b404c4a5d04faaf","max":227845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cd9d61cff487442b9effad1e9abbfba1","value":227845}},"51b5e31bb90149fa87e6c7a46c3ba28b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2c9753c7ada4105bb2fc578635f284c","placeholder":"​","style":"IPY_MODEL_a5e283f0d6384cf5b565359956a63f6d","value":" 223k/223k [00:00&lt;00:00, 6.47MB/s]"}},"acf35e2b012a4908bfa1b7684d84692a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0bda6b9fc294107b0974c8649cb3dfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06fcfa646f2341deb5e9baa825485f90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"710c1d0b690044f09b404c4a5d04faaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd9d61cff487442b9effad1e9abbfba1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f2c9753c7ada4105bb2fc578635f284c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5e283f0d6384cf5b565359956a63f6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b04f261a31264e6abd6832ece4948f3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d77ff91b3f7148469b0fca726b3fecb2","IPY_MODEL_efa12d957b894751a7d73fdce3a11a60","IPY_MODEL_9fedbb73b3e74b9abea3cc8813441107"],"layout":"IPY_MODEL_6793842716bf454d9f80df2f6cc9356c"}},"d77ff91b3f7148469b0fca726b3fecb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2848168a464448bbaffcab4d7d8f7ee3","placeholder":"​","style":"IPY_MODEL_546c6e1b31464fa6a980b43679ac24ac","value":"Downloading: 100%"}},"efa12d957b894751a7d73fdce3a11a60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c88474cf65246e1873c089f4f87ff19","max":442221694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a944bb3ff93f49e5adb2e08249463af5","value":442221694}},"9fedbb73b3e74b9abea3cc8813441107":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c359e21fe6084f7bb451ab2fb5907d21","placeholder":"​","style":"IPY_MODEL_cd57f986b77f4b408bb91bc66fe96bd1","value":" 422M/422M [00:12&lt;00:00, 62.5MB/s]"}},"6793842716bf454d9f80df2f6cc9356c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2848168a464448bbaffcab4d7d8f7ee3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"546c6e1b31464fa6a980b43679ac24ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c88474cf65246e1873c089f4f87ff19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a944bb3ff93f49e5adb2e08249463af5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c359e21fe6084f7bb451ab2fb5907d21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd57f986b77f4b408bb91bc66fe96bd1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a088d9f0b0142879032e03c2806908b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ca611188c3a415aac4e5d1ff0e556ce","IPY_MODEL_458de8e2e8fe46a9825d5e13b80a22c4","IPY_MODEL_9ebfd31e72e24da2b0b2ad189a16046a"],"layout":"IPY_MODEL_5f598822f7a8449f9ec41d1846453e74"}},"0ca611188c3a415aac4e5d1ff0e556ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2ad7dc7f26b40fb9df26dff16ff999b","placeholder":"​","style":"IPY_MODEL_b5286be853634ba6a5120ed027be73d6","value":"Downloading builder script: 100%"}},"458de8e2e8fe46a9825d5e13b80a22c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5acf1f9e0df4c6aaddb7a0486ab3054","max":5825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee99cc2548d5425e9b9c362e0bd775b2","value":5825}},"9ebfd31e72e24da2b0b2ad189a16046a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4c8db144dde48689e8e9f303c0ae2b5","placeholder":"​","style":"IPY_MODEL_889fb8c0408e4436a6f536d8ac2485c7","value":" 5.83k/5.83k [00:00&lt;00:00, 245kB/s]"}},"5f598822f7a8449f9ec41d1846453e74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2ad7dc7f26b40fb9df26dff16ff999b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5286be853634ba6a5120ed027be73d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5acf1f9e0df4c6aaddb7a0486ab3054":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee99cc2548d5425e9b9c362e0bd775b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f4c8db144dde48689e8e9f303c0ae2b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"889fb8c0408e4436a6f536d8ac2485c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"798dbc4ec8044e91aeae94b4d7888f4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1509974acb64513853e7918a2f6e250","IPY_MODEL_42816cb113fd496389bdc7c2366299f7","IPY_MODEL_4c1622b49b624dcdb6faf67d39781f69"],"layout":"IPY_MODEL_73811ca1a6784a8888ace5c12e7de025"}},"f1509974acb64513853e7918a2f6e250":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6746573afcfb4a1680dfe4c9fa9808af","placeholder":"​","style":"IPY_MODEL_bcf3958a87fe442097ee16ff7b0f0ef2","value":"Downloading metadata: 100%"}},"42816cb113fd496389bdc7c2366299f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a3b6f539c204e9b8a7f726ec55ea23a","max":3448,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f45ab7beef584c8c9d5e9bc57f3da47f","value":3448}},"4c1622b49b624dcdb6faf67d39781f69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec3f1738ccbd4420b2fc2afd91ccfb16","placeholder":"​","style":"IPY_MODEL_e7c46264ed8f4a73a290f8dcda46321d","value":" 3.45k/3.45k [00:00&lt;00:00, 212kB/s]"}},"73811ca1a6784a8888ace5c12e7de025":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6746573afcfb4a1680dfe4c9fa9808af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcf3958a87fe442097ee16ff7b0f0ef2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a3b6f539c204e9b8a7f726ec55ea23a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f45ab7beef584c8c9d5e9bc57f3da47f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec3f1738ccbd4420b2fc2afd91ccfb16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7c46264ed8f4a73a290f8dcda46321d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d973d5a5deea4bc193c6ed95f8ac1e82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4561af2cc0ab44d69b5067fdaab96095","IPY_MODEL_129dc291910e4b5788326ecd2dbda9ba","IPY_MODEL_6631b73a228b40d7bbc7e54cce86f2ea"],"layout":"IPY_MODEL_61b0062a44ca47178f04f0d1031d64f1"}},"4561af2cc0ab44d69b5067fdaab96095":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19feef6a1cd84bbdbb26f4b52dabe73e","placeholder":"​","style":"IPY_MODEL_e8c97c5540ec48d896dc78a23ab382df","value":"Downloading readme: 100%"}},"129dc291910e4b5788326ecd2dbda9ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26db51de410d4e01ac46418690839405","max":9698,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc8a40d4b7cd4b3c916acc0b6070aea3","value":9698}},"6631b73a228b40d7bbc7e54cce86f2ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b913fe19266d4a9794620de23ee604ff","placeholder":"​","style":"IPY_MODEL_e98e5e89ae684a76bbd3e47f88aa1a07","value":" 9.70k/9.70k [00:00&lt;00:00, 379kB/s]"}},"61b0062a44ca47178f04f0d1031d64f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19feef6a1cd84bbdbb26f4b52dabe73e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8c97c5540ec48d896dc78a23ab382df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26db51de410d4e01ac46418690839405":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc8a40d4b7cd4b3c916acc0b6070aea3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b913fe19266d4a9794620de23ee604ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e98e5e89ae684a76bbd3e47f88aa1a07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a45d884a8604cf49ef5e6cf308bbfbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_350586378fda483aba664b4d352546b2","IPY_MODEL_1a798c5b8c584bcea0f1b09c730f02cb","IPY_MODEL_62f20e042782402f81649938dde22444"],"layout":"IPY_MODEL_aa5d2ee3538e446b8180c94190418ad1"}},"350586378fda483aba664b4d352546b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d474deb13584625a7087a4a5792922a","placeholder":"​","style":"IPY_MODEL_0001d73aff254cc2be8220d5f625d13e","value":"Downloading data files: 100%"}},"1a798c5b8c584bcea0f1b09c730f02cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f818a411d6fe499e81464e3d5e4679b5","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41a1a4d33723447aa4f19f8921536757","value":3}},"62f20e042782402f81649938dde22444":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_82634e7ce59d4156abca84f2a5c961ce","placeholder":"​","style":"IPY_MODEL_46475a1560ef46d3b8e95d7d3f20ebe0","value":" 3/3 [00:04&lt;00:00,  1.49s/it]"}},"aa5d2ee3538e446b8180c94190418ad1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d474deb13584625a7087a4a5792922a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0001d73aff254cc2be8220d5f625d13e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f818a411d6fe499e81464e3d5e4679b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41a1a4d33723447aa4f19f8921536757":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"82634e7ce59d4156abca84f2a5c961ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46475a1560ef46d3b8e95d7d3f20ebe0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4dfd13497ad34c13be09821a30a37947":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_58b0fa9d33cb4e409e7484a99d3718f9","IPY_MODEL_4fdd238ecd3345fda14bc71fb5aea724","IPY_MODEL_90b005ca349f46818eb5889ad779535b"],"layout":"IPY_MODEL_4ceaa9d99194485fa037be0078843f33"}},"58b0fa9d33cb4e409e7484a99d3718f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b3f486080234649be25b9b5d7ff92ac","placeholder":"​","style":"IPY_MODEL_dad14e93411e4041a23225def1af11fa","value":"Downloading data: "}},"4fdd238ecd3345fda14bc71fb5aea724":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_424cb12c8815409da5c319b11486b459","max":283883,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30c9b5d7c90a4251890368cc8f0c52e5","value":283883}},"90b005ca349f46818eb5889ad779535b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b85a1db667c947f8b93089371532b8f0","placeholder":"​","style":"IPY_MODEL_c5fb5438613b473ea274f05343c1393b","value":" 1.14M/? [00:00&lt;00:00, 20.3MB/s]"}},"4ceaa9d99194485fa037be0078843f33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b3f486080234649be25b9b5d7ff92ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dad14e93411e4041a23225def1af11fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"424cb12c8815409da5c319b11486b459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30c9b5d7c90a4251890368cc8f0c52e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b85a1db667c947f8b93089371532b8f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5fb5438613b473ea274f05343c1393b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fadac24a681345aab79df79f93699644":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1418b4f5cc441ffb8aa5e2d1a8fe536","IPY_MODEL_66629eb67b5a4fa194909e06b8a9a22b","IPY_MODEL_3f924c59275944158ea3cad74de931f2"],"layout":"IPY_MODEL_b25ada84411046dd859770896a43c4ea"}},"d1418b4f5cc441ffb8aa5e2d1a8fe536":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb554b554025478787d9d226a4e4d87a","placeholder":"​","style":"IPY_MODEL_7a7a6a9ce5a34c87bb4e720caf154e5c","value":"Downloading data: "}},"66629eb67b5a4fa194909e06b8a9a22b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_805a1b3d27d84a9aabb6090d7830d78e","max":51200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69ed47d0e17b4a8f8b213e5cde02d691","value":51200}},"3f924c59275944158ea3cad74de931f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_912e5c2aeb7e4f61a0d2b5343a00cfbf","placeholder":"​","style":"IPY_MODEL_f4e5d14e6dda4a82a61dff2e405a1bd8","value":" 200k/? [00:00&lt;00:00, 3.37MB/s]"}},"b25ada84411046dd859770896a43c4ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb554b554025478787d9d226a4e4d87a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a7a6a9ce5a34c87bb4e720caf154e5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"805a1b3d27d84a9aabb6090d7830d78e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69ed47d0e17b4a8f8b213e5cde02d691":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"912e5c2aeb7e4f61a0d2b5343a00cfbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4e5d14e6dda4a82a61dff2e405a1bd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff83ab45e805404d9d66c0050da271cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92877ebdcc064b98b27ca3fdcea8695c","IPY_MODEL_4fae413c489b4257ab692373a0abdb53","IPY_MODEL_10847d518f8d413580cd6cd40eefeb39"],"layout":"IPY_MODEL_5a0076d589c041eaa81c669320f54050"}},"92877ebdcc064b98b27ca3fdcea8695c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_484d8defb6874fe5a00819ac240aab00","placeholder":"​","style":"IPY_MODEL_175d64d4ea1e4949b782291bc30d4075","value":"Downloading data: "}},"4fae413c489b4257ab692373a0abdb53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb3a28883c8a4772a518cf6e0dd2b580","max":52411,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a33033a066164223aefc6ede20dbd4e8","value":52411}},"10847d518f8d413580cd6cd40eefeb39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d60a91ea20a4007a048af0c02dfb334","placeholder":"​","style":"IPY_MODEL_436c8a604b1f4b67ab9a1a8f902ae875","value":" 206k/? [00:00&lt;00:00, 4.01MB/s]"}},"5a0076d589c041eaa81c669320f54050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"484d8defb6874fe5a00819ac240aab00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"175d64d4ea1e4949b782291bc30d4075":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb3a28883c8a4772a518cf6e0dd2b580":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a33033a066164223aefc6ede20dbd4e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d60a91ea20a4007a048af0c02dfb334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"436c8a604b1f4b67ab9a1a8f902ae875":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"681c78ceef3e4a6180acdba726206bcd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b006c29560c4ddfa88251222fedfe38","IPY_MODEL_055ca7cc9dc84526a1ed734b67492f10","IPY_MODEL_1eb120675114440695015f491901f647"],"layout":"IPY_MODEL_7932d67fb1e245fcb4bf4aef90b9f299"}},"9b006c29560c4ddfa88251222fedfe38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06bf1f89ddb243f39a10cabbe011179a","placeholder":"​","style":"IPY_MODEL_45557893bd674a3f852bce63b2ac7c4a","value":"Extracting data files: 100%"}},"055ca7cc9dc84526a1ed734b67492f10":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf739397926542ea97d2d004c00b438b","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6be6e0f52c2843fab68fe4f2281ff45f","value":3}},"1eb120675114440695015f491901f647":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5747abca28f45038a709239c56149e9","placeholder":"​","style":"IPY_MODEL_84aa73035c8443a88062517dee8f9cfe","value":" 3/3 [00:00&lt;00:00, 65.13it/s]"}},"7932d67fb1e245fcb4bf4aef90b9f299":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06bf1f89ddb243f39a10cabbe011179a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45557893bd674a3f852bce63b2ac7c4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf739397926542ea97d2d004c00b438b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6be6e0f52c2843fab68fe4f2281ff45f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5747abca28f45038a709239c56149e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84aa73035c8443a88062517dee8f9cfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a42dfbc6b2f34cf3a168d0f0c513eac1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf831c2f7f7f4571abca0489c25927b0","IPY_MODEL_27190639697547dbba180ed49be80798","IPY_MODEL_6403bdfc30fb48bca2930a16cd79bab6"],"layout":"IPY_MODEL_4a0917ada55240c59b13dd6566c119a9"}},"cf831c2f7f7f4571abca0489c25927b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_046d3b5f357846be9df735562f83d3a1","placeholder":"​","style":"IPY_MODEL_2edd6eb6dd154c92968e29821958f985","value":"Generating train split: 100%"}},"27190639697547dbba180ed49be80798":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3934c07d848e4a51ada4ec6ac4fe05e8","max":5433,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9820febb62f94f1d87746b87ef04ca02","value":5433}},"6403bdfc30fb48bca2930a16cd79bab6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30a9ff020fa84b0bbabc052d52e30358","placeholder":"​","style":"IPY_MODEL_6a88fbe9223f4bd1b49ec5e79efbd062","value":" 5433/5433 [00:02&lt;00:00, 2532.81 examples/s]"}},"4a0917ada55240c59b13dd6566c119a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"046d3b5f357846be9df735562f83d3a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2edd6eb6dd154c92968e29821958f985":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3934c07d848e4a51ada4ec6ac4fe05e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9820febb62f94f1d87746b87ef04ca02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30a9ff020fa84b0bbabc052d52e30358":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a88fbe9223f4bd1b49ec5e79efbd062":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0106b98a1964606bf83a3ffe130b226":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8ab8611237a4d6cb732d534cc2322b6","IPY_MODEL_a7a9c82388054bcdb8ecc9c422d741bb","IPY_MODEL_272e39b670fe4bb6b9dbb5ae4e18cc6f"],"layout":"IPY_MODEL_c14012b3bc454f8cbbb47c698fefeb3f"}},"e8ab8611237a4d6cb732d534cc2322b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_533f3bcb4a0148b689fde4052169cc7c","placeholder":"​","style":"IPY_MODEL_7f91cd1b50114664830628918891d3d9","value":"Generating validation split: 100%"}},"a7a9c82388054bcdb8ecc9c422d741bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_93f30ff688cd4654a0d84c3e6b0dc6a8","max":924,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09c53bc7b9d849559cdfc128a4a9c3f2","value":924}},"272e39b670fe4bb6b9dbb5ae4e18cc6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f3f2e9260634f65b3a2599afb3afb04","placeholder":"​","style":"IPY_MODEL_f7ae7dd7c11b458fb3f5694af088c04f","value":" 924/924 [00:00&lt;00:00, 2198.76 examples/s]"}},"c14012b3bc454f8cbbb47c698fefeb3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"533f3bcb4a0148b689fde4052169cc7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f91cd1b50114664830628918891d3d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93f30ff688cd4654a0d84c3e6b0dc6a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09c53bc7b9d849559cdfc128a4a9c3f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f3f2e9260634f65b3a2599afb3afb04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7ae7dd7c11b458fb3f5694af088c04f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5922f5ca274b486c92a1e678660e430b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2976b431b04a4309b08574197d78a650","IPY_MODEL_fe53e57d3031403f95b7814af640f5f1","IPY_MODEL_eca14e25cc2e46c597a6b9839e3e1f77"],"layout":"IPY_MODEL_d7e376a9d61b4a35b62d9d627253dc58"}},"2976b431b04a4309b08574197d78a650":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73ddacfd9f034b7786d043a940dd3e3c","placeholder":"​","style":"IPY_MODEL_e2fae04c32ce4dff9a897d05adb9a806","value":"Generating test split: 100%"}},"fe53e57d3031403f95b7814af640f5f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_250b81e633014ff39da1606024bd7c6f","max":941,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e6048090d32d414ca2f2f600497148ef","value":941}},"eca14e25cc2e46c597a6b9839e3e1f77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36ff535b73aa41cbb3f8aa8e680bc649","placeholder":"​","style":"IPY_MODEL_9d5efedfc60449a6ae8b20ac8852ed30","value":" 941/941 [00:00&lt;00:00, 1927.51 examples/s]"}},"d7e376a9d61b4a35b62d9d627253dc58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73ddacfd9f034b7786d043a940dd3e3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2fae04c32ce4dff9a897d05adb9a806":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"250b81e633014ff39da1606024bd7c6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6048090d32d414ca2f2f600497148ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36ff535b73aa41cbb3f8aa8e680bc649":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d5efedfc60449a6ae8b20ac8852ed30":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}